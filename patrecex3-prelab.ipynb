{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec059ca9",
   "metadata": {
    "_cell_guid": "f37f789f-3465-4cc2-82d8-22895f48b65b",
    "_uuid": "2182553a-a783-486b-8927-79ce5a6fdbed",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-02-20T21:18:57.772711Z",
     "iopub.status.busy": "2022-02-20T21:18:57.771029Z",
     "iopub.status.idle": "2022-02-20T21:19:01.028783Z",
     "shell.execute_reply": "2022-02-20T21:19:01.028074Z",
     "shell.execute_reply.started": "2022-02-20T21:04:16.905265Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 3.28823,
     "end_time": "2022-02-20T21:19:01.028946",
     "exception": false,
     "start_time": "2022-02-20T21:18:57.740716",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import re\n",
    "import os\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import random\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "# sklearn\n",
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, r2_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Pytorch\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import SubsetRandomSampler, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce34b537",
   "metadata": {
    "_cell_guid": "8d248c32-b7b6-41df-95c4-825647e90bc8",
    "_uuid": "10e016f8-e38b-461e-a684-b74d5ca29d3d",
    "papermill": {
     "duration": 0.024252,
     "end_time": "2022-02-20T21:19:01.080684",
     "exception": false,
     "start_time": "2022-02-20T21:19:01.056432",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49a32f9d",
   "metadata": {
    "_cell_guid": "c43069c8-65ff-4791-bfcc-320d3dfd1915",
    "_uuid": "ab0269c5-82aa-40df-a465-84abb20b37da",
    "papermill": {
     "duration": 0.023918,
     "end_time": "2022-02-20T21:19:01.129185",
     "exception": false,
     "start_time": "2022-02-20T21:19:01.105267",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Split the data in train and evaluation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d65d4f1d",
   "metadata": {
    "_cell_guid": "3770d2c6-4ce7-4c46-b020-f0539f06edb6",
    "_uuid": "39bfe2e6-4651-4302-a75c-d8cc7709eba4",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-02-20T21:19:01.185216Z",
     "iopub.status.busy": "2022-02-20T21:19:01.184329Z",
     "iopub.status.idle": "2022-02-20T21:19:01.187012Z",
     "shell.execute_reply": "2022-02-20T21:19:01.186518Z",
     "shell.execute_reply.started": "2022-02-20T21:04:20.450237Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.033913,
     "end_time": "2022-02-20T21:19:01.187120",
     "exception": false,
     "start_time": "2022-02-20T21:19:01.153207",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def torch_train_val_split(\n",
    "    dataset, batch_train, batch_eval, val_size=0.2, shuffle=True, seed=420\n",
    "):\n",
    "    # Creating data indices for training and validation splits:\n",
    "    dataset_size = len(dataset)\n",
    "    indices = list(range(dataset_size))\n",
    "    val_split = int(np.floor(val_size * dataset_size))\n",
    "    if shuffle:\n",
    "        np.random.seed(seed)\n",
    "        np.random.shuffle(indices)\n",
    "    train_indices = indices[val_split:]\n",
    "    val_indices = indices[:val_split]\n",
    "\n",
    "    # Creating PT data samplers and loaders:\n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    val_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "    train_loader = DataLoader(dataset, batch_size=batch_train, sampler=train_sampler)\n",
    "    val_loader = DataLoader(dataset, batch_size=batch_eval, sampler=val_sampler)\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cad82c3",
   "metadata": {
    "_cell_guid": "470d1098-3cdf-4660-85ef-53c784b9fed7",
    "_uuid": "b6c5233d-a272-4db8-920f-8cd8709570f2",
    "papermill": {
     "duration": 0.024687,
     "end_time": "2022-02-20T21:19:01.235927",
     "exception": false,
     "start_time": "2022-02-20T21:19:01.211240",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Read spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2504416",
   "metadata": {
    "_cell_guid": "c5397994-0d86-4f0c-aec8-e861138af5d1",
    "_uuid": "50ce75ce-4e7e-41c1-8150-8128bc3eb054",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-02-20T21:19:01.291000Z",
     "iopub.status.busy": "2022-02-20T21:19:01.290204Z",
     "iopub.status.idle": "2022-02-20T21:19:01.292527Z",
     "shell.execute_reply": "2022-02-20T21:19:01.292134Z",
     "shell.execute_reply.started": "2022-02-20T21:04:20.461297Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.031151,
     "end_time": "2022-02-20T21:19:01.292662",
     "exception": false,
     "start_time": "2022-02-20T21:19:01.261511",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_spectrogram(spectrogram_file, chroma=True, fused = False):\n",
    "\n",
    "    spectrograms = np.load(spectrogram_file)\n",
    "    \n",
    "    if not fused:\n",
    "        if chroma:\n",
    "            return spectrograms[128:].T\n",
    "        \n",
    "        return spectrograms[:128].T\n",
    "    \n",
    "    return spectrograms.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0fc089",
   "metadata": {
    "_cell_guid": "305104a6-1d39-43ab-8b67-afbad35cc8d9",
    "_uuid": "6db7d0e4-9c99-49ba-a6dd-6db7ec487bff",
    "papermill": {
     "duration": 0.023898,
     "end_time": "2022-02-20T21:19:01.341099",
     "exception": false,
     "start_time": "2022-02-20T21:19:01.317201",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Transform the labels to a different encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e88f4a1",
   "metadata": {
    "_cell_guid": "9ee5be47-93e9-4f39-b908-c48138fbc42a",
    "_uuid": "c69f8ccc-c37c-4722-84f5-3c866fdc8d52",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-02-20T21:19:01.395612Z",
     "iopub.status.busy": "2022-02-20T21:19:01.394765Z",
     "iopub.status.idle": "2022-02-20T21:19:01.396830Z",
     "shell.execute_reply": "2022-02-20T21:19:01.397222Z",
     "shell.execute_reply.started": "2022-02-20T21:04:20.474776Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.031877,
     "end_time": "2022-02-20T21:19:01.397353",
     "exception": false,
     "start_time": "2022-02-20T21:19:01.365476",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LabelTransformer(LabelEncoder):\n",
    "    def inverse(self, y):\n",
    "        try:\n",
    "            return super(LabelTransformer, self).inverse_transform(y)\n",
    "        except:\n",
    "            return super(LabelTransformer, self).inverse_transform([y])\n",
    "\n",
    "    def transform(self, y):\n",
    "        try:\n",
    "            return super(LabelTransformer, self).transform(y)\n",
    "        except:\n",
    "            return super(LabelTransformer, self).transform([y])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c143849c",
   "metadata": {
    "_cell_guid": "c3384626-c9d8-4a9c-b679-5f53897032dc",
    "_uuid": "19549422-3a5f-4c30-9150-eb3b1f1954cf",
    "papermill": {
     "duration": 0.02461,
     "end_time": "2022-02-20T21:19:01.445977",
     "exception": false,
     "start_time": "2022-02-20T21:19:01.421367",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Transform the frequency range to be the same for all spectrograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0cab5d0",
   "metadata": {
    "_cell_guid": "4d9b7bc5-70ba-40fa-8d92-e7e16e013178",
    "_uuid": "fbf4a941-1580-4a23-8e3f-210a91bdd1ab",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-02-20T21:19:01.501040Z",
     "iopub.status.busy": "2022-02-20T21:19:01.500503Z",
     "iopub.status.idle": "2022-02-20T21:19:01.503645Z",
     "shell.execute_reply": "2022-02-20T21:19:01.504064Z",
     "shell.execute_reply.started": "2022-02-20T21:04:20.484252Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.034085,
     "end_time": "2022-02-20T21:19:01.504193",
     "exception": false,
     "start_time": "2022-02-20T21:19:01.470108",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PaddingTransform(object):\n",
    "    def __init__(self, max_length, padding_value=0):\n",
    "        self.max_length = max_length\n",
    "        self.padding_value = padding_value\n",
    "\n",
    "    def __call__(self, s):\n",
    "        if len(s) == self.max_length:\n",
    "            return s\n",
    "\n",
    "        if len(s) > self.max_length:\n",
    "            return s[: self.max_length]\n",
    "\n",
    "        if len(s) < self.max_length:\n",
    "            s1 = copy.deepcopy(s)\n",
    "            pad = np.zeros((self.max_length - s.shape[0], s.shape[1]), dtype=np.float32)\n",
    "            s1 = np.vstack((s1, pad))\n",
    "            return s1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7a5864",
   "metadata": {
    "_cell_guid": "1dfe6474-da4a-4ff8-aa9c-6fdb0cbd8bef",
    "_uuid": "cbce7464-ac6e-4d96-82ed-358b486f6fda",
    "papermill": {
     "duration": 0.024284,
     "end_time": "2022-02-20T21:19:01.552883",
     "exception": false,
     "start_time": "2022-02-20T21:19:01.528599",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Create a dataset for the different spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "693b3efa",
   "metadata": {
    "_cell_guid": "939a045a-2bf2-4ea1-a73c-086f64bf9794",
    "_uuid": "ec6fd28a-6eaa-4198-a092-0298fdd9dc06",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-02-20T21:19:01.616955Z",
     "iopub.status.busy": "2022-02-20T21:19:01.615360Z",
     "iopub.status.idle": "2022-02-20T21:19:01.617500Z",
     "shell.execute_reply": "2022-02-20T21:19:01.617933Z",
     "shell.execute_reply.started": "2022-02-20T21:04:20.496518Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.040755,
     "end_time": "2022-02-20T21:19:01.618057",
     "exception": false,
     "start_time": "2022-02-20T21:19:01.577302",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SpectrogramDataset(Dataset):\n",
    "    def __init__(\n",
    "        self, path, class_mapping=None, train=True, max_length=-1, read_spec = read_spectrogram, chroma = True, fused = False,\n",
    "    label_index = 1):\n",
    "        t = \"train\" if train else \"test\"\n",
    "        p = os.path.join(path, t)\n",
    "        \n",
    "        self.label_index = label_index\n",
    "        self.index = os.path.join(path, \"{}_labels.txt\".format(t))\n",
    "        self.files, labels = self.get_files_labels(self.index, class_mapping)\n",
    "        self.feats = [read_spec(os.path.join(p, f), chroma= chroma, fused = fused) for f in self.files]\n",
    "        self.feat_dim = self.feats[0].shape[1]\n",
    "        self.lengths = [len(i) for i in self.feats]\n",
    "        self.max_length = max(self.lengths) if max_length <= 0 else max_length\n",
    "        self.zero_pad_and_stack = PaddingTransform(self.max_length)\n",
    "        self.label_transformer = LabelTransformer()\n",
    "        if isinstance(labels, (list, tuple)):\n",
    "            \n",
    "            try:\n",
    "                float(labels[0])\n",
    "                self.labels = np.array(labels).astype('float64')\n",
    "                \n",
    "            except:\n",
    "                self.labels = np.array(\n",
    "                    self.label_transformer.fit_transform(labels).astype(\"int64\"))\n",
    "            \n",
    "\n",
    "    def get_files_labels(self, txt, class_mapping):\n",
    "        with open(txt, \"r\") as fd:\n",
    "            lines = [l.rstrip().split(\"\\t\") if '\\t' in l else l.rstrip().split(\",\") for l in fd.readlines()[1:]]\n",
    "        files, labels = [], []\n",
    "        \n",
    "        for l in lines:\n",
    "            label = l[self.label_index]\n",
    "            if class_mapping:\n",
    "                label = class_mapping[l[self.label_index]]\n",
    "            if not label:\n",
    "                continue\n",
    "            # Kaggle automatically unzips the npy.gz format so this hack is needed\n",
    "            _id = l[0].split('.')[0]\n",
    "            npy_file = '{}.fused.full.npy'.format(_id)\n",
    "            files.append(npy_file)\n",
    "            labels.append(label)\n",
    "        return files, labels\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        length = min(self.lengths[item], self.max_length)\n",
    "        return self.zero_pad_and_stack(self.feats[item]), self.labels[item], length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b624b438",
   "metadata": {
    "_cell_guid": "1f19b215-09df-4e57-9f70-9ee132a26ee8",
    "_uuid": "a47ce035-1990-4f04-a7a6-fce7646c68a6",
    "papermill": {
     "duration": 0.024152,
     "end_time": "2022-02-20T21:19:01.666273",
     "exception": false,
     "start_time": "2022-02-20T21:19:01.642121",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Create mel spectrogram datasets (train and set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f718c32",
   "metadata": {
    "_cell_guid": "990af372-aa39-4b61-a3cb-5c7293c093b9",
    "_uuid": "cfd27439-dcd1-4e48-8b01-e99acf1ab334",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-02-20T21:19:01.723700Z",
     "iopub.status.busy": "2022-02-20T21:19:01.722910Z",
     "iopub.status.idle": "2022-02-20T21:19:01.725386Z",
     "shell.execute_reply": "2022-02-20T21:19:01.724919Z",
     "shell.execute_reply.started": "2022-02-20T21:04:20.517399Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.034894,
     "end_time": "2022-02-20T21:19:01.725519",
     "exception": false,
     "start_time": "2022-02-20T21:19:01.690625",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class_mapping = {\n",
    "    \"Rock\": \"Rock\",\n",
    "    \"Psych-Rock\": \"Rock\",\n",
    "    \"Indie-Rock\": None,\n",
    "    \"Post-Rock\": \"Rock\",\n",
    "    \"Psych-Folk\": \"Folk\",\n",
    "    \"Folk\": \"Folk\",\n",
    "    \"Metal\": \"Metal\",\n",
    "    \"Punk\": \"Metal\",\n",
    "    \"Post-Punk\": None,\n",
    "    \"Trip-Hop\": \"Trip-Hop\",\n",
    "    \"Pop\": \"Pop\",\n",
    "    \"Electronic\": \"Electronic\",\n",
    "    \"Hip-Hop\": \"Hip-Hop\",\n",
    "    \"Classical\": \"Classical\",\n",
    "    \"Blues\": \"Blues\",\n",
    "    \"Chiptune\": \"Electronic\",\n",
    "    \"Jazz\": \"Jazz\",\n",
    "    \"Soundtrack\": None,\n",
    "    \"International\": None,\n",
    "    \"Old-Time\": None,\n",
    "    }\n",
    "def train_test_val_splitter(directory, class_mapping = class_mapping, chroma=False, fused=False):\n",
    "    \n",
    "    train_specs = SpectrogramDataset(directory, train = True, class_mapping = class_mapping, max_length = -1, read_spec=read_spectrogram, chroma=chroma, fused = fused)\n",
    "    inputs, _, _ = next(iter(train_specs))\n",
    "    test_specs = SpectrogramDataset(directory, train = False, class_mapping = class_mapping, max_length = inputs.shape[0], read_spec=read_spectrogram, chroma=chroma, fused = fused)\n",
    "    \n",
    "    train_loader, val_loader = torch_train_val_split(train_specs, 32 ,32, val_size=.33)\n",
    "    test_loader = DataLoader(test_specs, batch_size=32)\n",
    "    \n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f853d05",
   "metadata": {
    "_cell_guid": "f8d265a9-3259-4ae7-8baf-8cad96ba66a4",
    "_uuid": "77bb1f08-dfdb-4d96-ac5a-4de1ae7eb8b1",
    "execution": {
     "iopub.execute_input": "2022-02-20T21:19:01.803822Z",
     "iopub.status.busy": "2022-02-20T21:19:01.788338Z",
     "iopub.status.idle": "2022-02-20T21:19:01.806368Z",
     "shell.execute_reply": "2022-02-20T21:19:01.805893Z",
     "shell.execute_reply.started": "2022-02-20T21:04:20.532809Z"
    },
    "papermill": {
     "duration": 0.057002,
     "end_time": "2022-02-20T21:19:01.806500",
     "exception": false,
     "start_time": "2022-02-20T21:19:01.749498",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class BasicLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, rnn_size, output_dim, num_layers, bidirectional=False, dropout=0):\n",
    "        super(BasicLSTM, self).__init__()\n",
    "        self.bidirectional = bidirectional\n",
    "        self.rnn_size = rnn_size\n",
    "        self.feature_size = rnn_size * 2 if self.bidirectional else rnn_size\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        # --------------- Insert your code here ---------------- #\n",
    "        # Initialize the LSTM, Dropout, Output layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_dim, self.rnn_size, self.num_layers, bidirectional=self.bidirectional, batch_first=True, dropout=self.dropout)\n",
    "        self.linear = nn.Linear(self.feature_size, output_dim)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        \"\"\" \n",
    "            x : 3D numpy array of dimension N x L x D\n",
    "                N: batch index\n",
    "                L: sequence index\n",
    "                D: feature index\n",
    "\n",
    "            lengths: N x 1\n",
    "         \"\"\"\n",
    "        \n",
    "        # --------------- Insert your code here ---------------- #\n",
    "        # Obtain the model's device ID\n",
    "        DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        # You must have all of the outputs of the LSTM, but you need only the last one (that does not exceed the sequence length)\n",
    "        # To get it use the last_timestep method\n",
    "        # Then pass it through the remaining network\n",
    "        \n",
    "        if self.bidirectional:\n",
    "            h0 = torch.zeros(self.num_layers*2, x.size(0), self.rnn_size).double().to(DEVICE)\n",
    "            c0 = torch.zeros(self.num_layers*2, x.size(0), self.rnn_size).double().to(DEVICE)\n",
    "        else:\n",
    "            h0 = torch.zeros(self.num_layers, x.size(0), self.rnn_size).double().to(DEVICE)\n",
    "            c0 = torch.zeros(self.num_layers, x.size(0), self.rnn_size).double().to(DEVICE)\n",
    "            \n",
    "        # Forward propagate LSTM\n",
    "        lstm_out, _ = self.lstm(x, (h0, c0))\n",
    "\n",
    "        # Forward propagate Linear\n",
    "        last_outputs = self.linear(self.last_timestep(lstm_out, lengths, self.bidirectional))\n",
    "        return last_outputs\n",
    "\n",
    "    def last_timestep(self, outputs, lengths, bidirectional=False):\n",
    "        \"\"\"\n",
    "            Returns the last output of the LSTM taking into account the zero padding\n",
    "        \"\"\"\n",
    "        if bidirectional:\n",
    "            forward, backward = self.split_directions(outputs)\n",
    "            last_forward = self.last_by_index(forward, lengths)\n",
    "            last_backward = backward[:, 0, :]\n",
    "            # Concatenate and return - maybe add more functionalities like average\n",
    "            return torch.cat((last_forward, last_backward), dim=-1)\n",
    "\n",
    "        else:\n",
    "            return self.last_by_index(outputs, lengths)\n",
    "\n",
    "    @staticmethod\n",
    "    def split_directions(outputs):\n",
    "        direction_size = int(outputs.size(-1) / 2)\n",
    "        forward = outputs[:, :, :direction_size]\n",
    "        backward = outputs[:, :, direction_size:]\n",
    "        return forward, backward\n",
    "\n",
    "    @staticmethod\n",
    "    def last_by_index(outputs, lengths):\n",
    "        # Obtain the model's device ID\n",
    "        DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        # Index of the last output for each sequence.\n",
    "        idx = (lengths - 1).view(-1, 1).expand(outputs.size(0),\n",
    "                                               outputs.size(2)).unsqueeze(1).to(DEVICE)\n",
    "        return outputs.gather(1, idx).squeeze()\n",
    "    \n",
    "    \n",
    "    def fit(self, epochs, dataloader, loss_function, optimizer, model_name, batch_overfit = False):\n",
    "    \n",
    "        # Οbtain the model's device ID\n",
    "        device = next(self.parameters()).device\n",
    "\n",
    "        # IMPORTANT: switch to train mode\n",
    "        # Εnable regularization layers, such as Dropout\n",
    "        self.train()\n",
    "\n",
    "        batch_overfit = [next(iter(dataloader))]\n",
    "        loader = dataloader if not batch_overfit else batch_overfit\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            running_loss = 0.0\n",
    "\n",
    "            for index, batch in enumerate(loader, 1):\n",
    "                # Get the inputs (batch)\n",
    "                inputs, labels, lengths = batch\n",
    "                inputs = inputs.double()\n",
    "                    \n",
    "                # Move the batch tensors to the right device\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                # Step 1 - zero the gradients\n",
    "                # Remember that PyTorch accumulates gradients.\n",
    "                # We need to clear them out before each batch!\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Step 2 - forward pass: y' = model(x)\n",
    "                y_preds = self(inputs, lengths)\n",
    "                # Step 3 - compute loss: L = loss_function(y, y')\n",
    "                if (isinstance(loss_function, nn.MSELoss)): \n",
    "                    labels = torch.unsqueeze(labels, 1)\n",
    "                    loss = loss_function(y_preds, labels.double())\n",
    "                    \n",
    "                else:\n",
    "                    loss = loss_function(y_preds, labels)\n",
    "\n",
    "\n",
    "                # Step 4 - backward pass: compute gradient wrt model parameters\n",
    "                loss.backward()\n",
    "\n",
    "                # Step 5 - update weights\n",
    "                optimizer.step()\n",
    "\n",
    "                # Accumulate loss in a variable.\n",
    "                running_loss += loss.data.item()\n",
    "\n",
    "\n",
    "                indicator = epoch if batch_overfit else index\n",
    "                if (indicator % 100 == 0):\n",
    "                    print(f'Epoch : {epoch}, Batch : {index}, Running Loss : {running_loss / index}')\n",
    "\n",
    "        torch.save(self, model_name)\n",
    "\n",
    "    def evaluate(self, dataloader, loss_function):\n",
    "        # IMPORTANT: switch to eval mode\n",
    "        # Disable regularization layers, such as Dropout\n",
    "        self.eval()\n",
    "        acc = 0.0\n",
    "        samples = 0 \n",
    "\n",
    "        y_pred = []  # the predicted labels\n",
    "        y = []  # the gold labels\n",
    "\n",
    "        # Obtain the model's device ID\n",
    "        device = next(self.parameters()).device\n",
    "\n",
    "        # IMPORTANT: in evaluation mode, we don't want to keep the gradients\n",
    "        # so we do everything under torch.no_grad()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for index, batch in enumerate(dataloader, 1):\n",
    "                # Get the inputs (batch)\n",
    "                inputs, labels, lengths = batch\n",
    "                # Step 1 - move the batch tensors to the right device\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Step 2 - forward pass: y' = model(x)\n",
    "                y_preds = self(inputs, lengths)  # EX9\n",
    "\n",
    "                # Step 3 - compute loss: L = loss_function(y, y')\n",
    "                # We compute the loss only for inspection (compare train/test loss)\n",
    "                # because we do not actually backpropagate in test time\n",
    "                # loss = loss_function(y_preds, labels)\n",
    "\n",
    "                # Step 4 - make predictions (class = argmax of posteriors)\n",
    "                if isinstance(loss_function, nn.CrossEntropyLoss):\n",
    "                    y_preds_arg = torch.argmax(y_preds, dim=1)\n",
    "                \n",
    "                elif isinstance(loss_function, nn.MSELoss):\n",
    "                    y_preds_arg = y_preds\n",
    "\n",
    "                # Step 5 - collect the predictions, gold labels and batch loss\n",
    "                y_pred.append(y_preds_arg.cpu().numpy())\n",
    "                y.append(labels.cpu().numpy())\n",
    "\n",
    "                # Compute accuracy \n",
    "                # acc += (labels == y_preds_arg).sum().detach().item()\n",
    "                # samples += inputs.size(0)\n",
    "\n",
    "\n",
    "\n",
    "        # print(f'Accuracy: {acc / samples}')\n",
    "\n",
    "        y_pred = [elem for sublist in y_pred for elem in sublist]\n",
    "        y = [elem for sublist in y for elem in sublist]\n",
    "\n",
    "        return y_pred, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86ff1075",
   "metadata": {
    "_cell_guid": "e3ed2b61-b21c-45b4-9fa6-4424726008ee",
    "_uuid": "a4ed8ba4-dfb0-4f5f-b9fb-a95752390c5c",
    "execution": {
     "iopub.execute_input": "2022-02-20T21:19:01.864307Z",
     "iopub.status.busy": "2022-02-20T21:19:01.863497Z",
     "iopub.status.idle": "2022-02-20T21:19:01.866098Z",
     "shell.execute_reply": "2022-02-20T21:19:01.865694Z",
     "shell.execute_reply.started": "2022-02-20T21:04:20.570192Z"
    },
    "papermill": {
     "duration": 0.034559,
     "end_time": "2022-02-20T21:19:01.866210",
     "exception": false,
     "start_time": "2022-02-20T21:19:01.831651",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_eval_model(EPOCHS, model, model_name, dataset):\n",
    "    \n",
    "    train_dataset_str = 'train_' + dataset\n",
    "    test_dataset_str = 'test_' + dataset\n",
    "    val_dataset_str = 'val_' + dataset\n",
    "    \n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # model.double()\n",
    "    model.to(DEVICE)\n",
    "    loss_function = nn.CrossEntropyLoss().to(DEVICE)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001,  weight_decay=1e-5)\n",
    "\n",
    "    model.fit(EPOCHS, datasets[train_dataset_str], loss_function, optimizer, model_name = model_name)\n",
    "\n",
    "    y_train_true, y_train_pred = model.evaluate(datasets[train_dataset_str], loss_function)\n",
    "    y_val_true, y_val_pred = model.evaluate(datasets[val_dataset_str], loss_function)\n",
    "    print()\n",
    "    print(\"Accuracy for train:\" , accuracy_score(y_train_true, y_train_pred))\n",
    "    print(\"Accuracy for validation:\" , accuracy_score(y_val_true, y_val_pred))\n",
    "    print()\n",
    "    y_test_true, y_test_pred = model.evaluate(datasets[test_dataset_str], loss_function)\n",
    "\n",
    "    print(classification_report(y_test_true, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5eb070d6",
   "metadata": {
    "_cell_guid": "4d7d7e28-186a-4e40-97d2-5a0e11497c8a",
    "_uuid": "dc24bb61-aaee-4b47-99d0-e483a0504efa",
    "execution": {
     "iopub.execute_input": "2022-02-20T21:19:01.937931Z",
     "iopub.status.busy": "2022-02-20T21:19:01.918377Z",
     "iopub.status.idle": "2022-02-20T21:19:01.940144Z",
     "shell.execute_reply": "2022-02-20T21:19:01.939745Z",
     "shell.execute_reply.started": "2022-02-20T21:04:20.586928Z"
    },
    "papermill": {
     "duration": 0.049853,
     "end_time": "2022-02-20T21:19:01.940272",
     "exception": false,
     "start_time": "2022-02-20T21:19:01.890419",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_features, output_size = 10):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 4, 3, device = 'cpu')\n",
    "        y = num_features - 3 + 1\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        y = (y - 2)/2 + 1\n",
    "        self.norm1 = nn.BatchNorm2d(4, device = 'cpu')\n",
    "        self.conv2 = nn.Conv2d(4, 8, 3, device = 'cpu')\n",
    "        y = y - 3 + 1\n",
    "        y = (y - 2) / 2 + 1\n",
    "        y = y.apply_(int)\n",
    "        \n",
    "        self.norm2 = nn.BatchNorm2d(8, device = 'cpu')\n",
    "        self.fc1 = nn.Linear(int(8 * torch.prod(y).item()), 120, device = 'cpu')\n",
    "        self.fc2 = nn.Linear(120, 84, device = 'cpu')\n",
    "        self.fc3 = nn.Linear(84, output_size, device = 'cpu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        if isinstance(loss_function, nn.MSELoss):\n",
    "            \n",
    "            x = torch.unsqueeze(x, 1).double()\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            x = torch.unsqueeze(x, 1).float()\n",
    "            \n",
    "        x = self.norm1(self.pool(F.relu(self.conv1(x))))\n",
    "        x = self.norm2(self.pool(F.relu(self.conv2(x))))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def fit(self, epochs, dataloader, loss_function, optimizer, model_name, batch_overfit = False):\n",
    "    \n",
    "        # Οbtain the model's device ID\n",
    "        device = next(self.parameters()).device\n",
    "\n",
    "        # IMPORTANT: switch to train mode\n",
    "        # Εnable regularization layers, such as Dropout\n",
    "        self.train()\n",
    "\n",
    "        batch_overfit = [next(iter(dataloader))]\n",
    "        loader = dataloader if not batch_overfit else batch_overfit\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            running_loss = 0.0\n",
    "\n",
    "            for index, batch in enumerate(loader, 1):\n",
    "\n",
    "                # Get the inputs (batch)\n",
    "                inputs, labels, lengths = batch                \n",
    "                if isinstance(loss_function, nn.MSELoss): \n",
    "                    labels = torch.unsqueeze(labels, 1)\n",
    "                    labels = labels.double()\n",
    "\n",
    "                # Move the batch tensors to the right device\n",
    "                inputs = inputs.to(device)\n",
    "                # inputs = inputs.double()\n",
    "                labels = labels.to(device)\n",
    "             \n",
    "\n",
    "                # Step 1 - zero the gradients\n",
    "                # Remember that PyTorch accumulates gradients.\n",
    "                # We need to clear them out before each batch!\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Step 2 - forward pass: y' = model(x)\n",
    "                y_preds = self(inputs)\n",
    "\n",
    "                # Step 3 - compute loss: L = loss_function(y, y')\n",
    "                loss = loss_function(y_preds, labels)\n",
    "\n",
    "                # Step 4 - backward pass: compute gradient wrt model parameters\n",
    "                loss.backward()\n",
    "\n",
    "                # Step 5 - update weights\n",
    "                optimizer.step()\n",
    "\n",
    "                # Accumulate loss in a variable.\n",
    "                running_loss += loss.data.item()\n",
    "\n",
    "\n",
    "                indicator = epoch if batch_overfit else index\n",
    "                if (indicator % 100 == 0):\n",
    "                    print(f'Epoch : {epoch}, Batch : {index}, Running Loss : {running_loss / index}')\n",
    "\n",
    "        torch.save(self, model_name)\n",
    "\n",
    "    def evaluate(self, dataloader, loss_function):\n",
    "        # IMPORTANT: switch to eval mode\n",
    "        # Disable regularization layers, such as Dropout\n",
    "        self.eval()\n",
    "        acc = 0.0\n",
    "        samples = 0 \n",
    "\n",
    "        y_pred = []  # the predicted labels\n",
    "        y = []  # the gold labels\n",
    "\n",
    "        # Obtain the model's device ID\n",
    "        device = next(self.parameters()).device\n",
    "\n",
    "        # IMPORTANT: in evaluation mode, we don't want to keep the gradients\n",
    "        # so we do everything under torch.no_grad()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for index, batch in enumerate(dataloader, 1):\n",
    "                # Get the inputs (batch)\n",
    "                inputs, labels, lengths = batch\n",
    "                # Step 1 - move the batch tensors to the right device\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                # Step 2 - forward pass: y' = model(x)\n",
    "                y_preds = self(inputs)  # EX9\n",
    "\n",
    "                # Step 3 - compute loss: L = loss_function(y, y')\n",
    "                # We compute the loss only for inspection (compare train/test loss)\n",
    "                # because we do not actually backpropagate in test time\n",
    "                # loss = loss_function(y_preds, labels)\n",
    "\n",
    "                # Step 4 - make predictions (class = argmax of posteriors)\n",
    "                if isinstance(loss_function, nn.MSELoss):\n",
    "                    y_preds_args = y_preds\n",
    "                elif isinstance(loss_function, nn.CrossEntropyLoss):\n",
    "                    y_preds_arg = torch.argmax(y_preds, dim=1)\n",
    "\n",
    "                # Step 5 - collect the predictions, gold labels and batch loss\n",
    "                y_pred.append(y_preds_arg.cpu().numpy())\n",
    "                y.append(labels.cpu().numpy())\n",
    "\n",
    "                # Compute accuracy \n",
    "                # acc += (labels == y_preds_arg).sum().detach().item()\n",
    "                # samples += inputs.size(0)\n",
    "\n",
    "\n",
    "\n",
    "        # print(f'Accuracy: {acc / samples}')\n",
    "\n",
    "        y_pred = [elem for sublist in y_pred for elem in sublist]\n",
    "        y = [elem for sublist in y for elem in sublist]\n",
    "\n",
    "        return y_pred, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d680a97e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T21:19:02.041761Z",
     "iopub.status.busy": "2022-02-20T21:19:02.040928Z",
     "iopub.status.idle": "2022-02-20T21:20:06.197687Z",
     "shell.execute_reply": "2022-02-20T21:20:06.198109Z",
     "shell.execute_reply.started": "2022-02-20T21:04:20.619783Z"
    },
    "papermill": {
     "duration": 64.233388,
     "end_time": "2022-02-20T21:20:06.198289",
     "exception": false,
     "start_time": "2022-02-20T21:19:01.964901",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "directory_beat = '../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms_beat/'\n",
    "directory = '../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms/'\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "train_loader_mel, val_loader_mel, test_loader_mel = train_test_val_splitter(directory)\n",
    "train_loader_beat_mel, val_loader_beat_mel, test_loader_beat_mel = train_test_val_splitter(directory_beat)\n",
    "train_loader_beat_chroma, val_loader_beat_chroma, test_loader_beat_chroma = train_test_val_splitter(directory_beat, chroma = True)\n",
    "train_loader, val_loader, test_loader = train_test_val_splitter(directory_beat, fused = True)\n",
    "\n",
    "datasets = {\n",
    "    'train_loader_mel': train_loader_mel,\n",
    "    'train_loader_beat_mel': train_loader_beat_mel,\n",
    "    'train_loader_beat_chroma': train_loader_beat_chroma,\n",
    "    'train_loader': train_loader,\n",
    "    'test_loader_mel': test_loader_mel,\n",
    "    'test_loader_beat_mel': test_loader_beat_mel,\n",
    "    'test_loader_beat_chroma': test_loader_beat_chroma,\n",
    "    'test_loader': test_loader,\n",
    "    'val_loader_mel': val_loader_mel,\n",
    "    'val_loader_beat_mel': val_loader_beat_mel,\n",
    "    'val_loader_beat_chroma': val_loader_beat_chroma,\n",
    "    'val_loader': val_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d708606",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T21:20:06.256147Z",
     "iopub.status.busy": "2022-02-20T21:20:06.255486Z",
     "iopub.status.idle": "2022-02-20T21:20:31.720368Z",
     "shell.execute_reply": "2022-02-20T21:20:31.719887Z",
     "shell.execute_reply.started": "2022-02-20T21:05:28.309355Z"
    },
    "papermill": {
     "duration": 25.497002,
     "end_time": "2022-02-20T21:20:31.720509",
     "exception": false,
     "start_time": "2022-02-20T21:20:06.223507",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, Batch : 1, Running Loss : 2.291560411453247\n",
      "Epoch : 100, Batch : 1, Running Loss : 3.022843156941235e-05\n",
      "Epoch : 200, Batch : 1, Running Loss : 1.815612085920293e-05\n",
      "Epoch : 300, Batch : 1, Running Loss : 1.2401030289765913e-05\n",
      "Epoch : 400, Batch : 1, Running Loss : 4.418142452777829e-06\n"
     ]
    }
   ],
   "source": [
    "num_features = next(iter(train_loader_mel))[0].size()[1:]\n",
    "num_features = torch.tensor(num_features)\n",
    "net = Net(num_features = num_features)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# net.double()\n",
    "net.to(DEVICE)\n",
    "loss_function = nn.CrossEntropyLoss().to(DEVICE)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001,  weight_decay=1e-5)\n",
    "\n",
    "net.fit(500, train_loader_mel, loss_function, optimizer, './overtrained', batch_overfit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6623dc9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T21:20:31.779074Z",
     "iopub.status.busy": "2022-02-20T21:20:31.778240Z",
     "iopub.status.idle": "2022-02-20T21:20:53.453701Z",
     "shell.execute_reply": "2022-02-20T21:20:53.452742Z",
     "shell.execute_reply.started": "2022-02-20T21:05:54.628478Z"
    },
    "papermill": {
     "duration": 21.706617,
     "end_time": "2022-02-20T21:20:53.453876",
     "exception": false,
     "start_time": "2022-02-20T21:20:31.747259",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, Batch : 1, Running Loss : 2.284116268157959\n",
      "Epoch : 100, Batch : 1, Running Loss : 1.3299228385221795e-06\n",
      "Epoch : 200, Batch : 1, Running Loss : 5.699683924831334e-07\n",
      "Epoch : 300, Batch : 1, Running Loss : 3.762539222407213e-07\n",
      "Epoch : 400, Batch : 1, Running Loss : 2.719459928357537e-07\n",
      "\n",
      "Accuracy for train: 0.1883495145631068\n",
      "Accuracy for validation: 0.1736842105263158\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.07      0.08        55\n",
      "           1       0.55      0.29      0.38        76\n",
      "           2       0.17      0.20      0.19        71\n",
      "           3       0.01      0.09      0.02        11\n",
      "           4       0.07      0.27      0.12        11\n",
      "           5       0.00      0.00      0.00        17\n",
      "           6       0.24      0.26      0.25        73\n",
      "           7       0.42      0.09      0.15       183\n",
      "           8       0.11      0.44      0.17        25\n",
      "           9       0.29      0.19      0.23        53\n",
      "\n",
      "    accuracy                           0.18       575\n",
      "   macro avg       0.20      0.19      0.16       575\n",
      "weighted avg       0.30      0.18      0.19       575\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_features = next(iter(train_loader_mel))[0].size()[1:]\n",
    "num_features = torch.tensor(num_features)\n",
    "net = Net(num_features = num_features)\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss().to(DEVICE)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr = 0.001)\n",
    "\n",
    "train_eval_model(500, net, './cnn_500_mel', 'loader_mel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fea54034",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T21:20:53.516020Z",
     "iopub.status.busy": "2022-02-20T21:20:53.515230Z",
     "iopub.status.idle": "2022-02-20T21:21:30.735100Z",
     "shell.execute_reply": "2022-02-20T21:21:30.734466Z",
     "shell.execute_reply.started": "2022-02-20T21:06:17.555141Z"
    },
    "papermill": {
     "duration": 37.252504,
     "end_time": "2022-02-20T21:21:30.735279",
     "exception": false,
     "start_time": "2022-02-20T21:20:53.482775",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, Batch : 1, Running Loss : 4.993778705596924\n",
      "Epoch : 100, Batch : 1, Running Loss : 9.685719533081283e-07\n",
      "Epoch : 200, Batch : 1, Running Loss : 4.023306701128604e-07\n",
      "Epoch : 300, Batch : 1, Running Loss : 2.607700650969491e-07\n",
      "Epoch : 400, Batch : 1, Running Loss : 2.4214369886976783e-07\n",
      "Epoch : 500, Batch : 1, Running Loss : 2.235172900100224e-07\n",
      "Epoch : 600, Batch : 1, Running Loss : 2.3841846541472478e-07\n",
      "Epoch : 700, Batch : 1, Running Loss : 1.415610029198433e-07\n",
      "Epoch : 800, Batch : 1, Running Loss : 1.415610029198433e-07\n",
      "Epoch : 900, Batch : 1, Running Loss : 1.4901158351676713e-07\n",
      "\n",
      "Accuracy for train: 0.2524271844660194\n",
      "Accuracy for validation: 0.23421052631578948\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.33      0.15      0.20        88\n",
      "           2       0.55      0.27      0.36       165\n",
      "           3       0.03      0.67      0.05         3\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.10      0.05      0.07        82\n",
      "           6       0.06      0.19      0.10        26\n",
      "           7       0.05      0.03      0.04        67\n",
      "           8       0.38      0.34      0.36       114\n",
      "           9       0.15      0.17      0.16        29\n",
      "\n",
      "    accuracy                           0.20       575\n",
      "   macro avg       0.16      0.19      0.13       575\n",
      "weighted avg       0.31      0.20      0.23       575\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "train_eval_model(1000, net, './cnn_1000_mel', 'loader_mel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b8a1b99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T21:21:30.804560Z",
     "iopub.status.busy": "2022-02-20T21:21:30.803799Z",
     "iopub.status.idle": "2022-02-20T21:21:32.713106Z",
     "shell.execute_reply": "2022-02-20T21:21:32.713521Z",
     "shell.execute_reply.started": "2022-02-20T21:06:56.709344Z"
    },
    "papermill": {
     "duration": 1.946042,
     "end_time": "2022-02-20T21:21:32.713701",
     "exception": false,
     "start_time": "2022-02-20T21:21:30.767659",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, Batch : 1, Running Loss : 2.3250396251678467\n",
      "Epoch : 100, Batch : 1, Running Loss : 0.0012120764004066586\n",
      "Epoch : 200, Batch : 1, Running Loss : 0.0002377933415118605\n",
      "Epoch : 300, Batch : 1, Running Loss : 4.872088902629912e-05\n",
      "Epoch : 400, Batch : 1, Running Loss : 2.9689817893086e-05\n",
      "\n",
      "Accuracy for train: 0.2058252427184466\n",
      "Accuracy for validation: 0.1881578947368421\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.05      0.14      0.07        14\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.61      0.23      0.33       215\n",
      "           4       0.20      0.21      0.21        38\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.68      0.22      0.33       244\n",
      "           7       0.10      0.09      0.09        45\n",
      "           8       0.01      0.07      0.02        14\n",
      "           9       0.06      0.40      0.10         5\n",
      "\n",
      "    accuracy                           0.21       575\n",
      "   macro avg       0.17      0.14      0.12       575\n",
      "weighted avg       0.54      0.21      0.29       575\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_features = next(iter(train_loader_beat_chroma))[0].size()[1:]\n",
    "num_features = torch.tensor(num_features)\n",
    "net = Net(num_features = num_features)\n",
    "train_eval_model(500, net, './cnn_500_mel', 'loader_beat_chroma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fbb6b6e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T21:21:32.782568Z",
     "iopub.status.busy": "2022-02-20T21:21:32.781749Z",
     "iopub.status.idle": "2022-02-20T21:21:35.967711Z",
     "shell.execute_reply": "2022-02-20T21:21:35.968589Z",
     "shell.execute_reply.started": "2022-02-20T21:06:59.435590Z"
    },
    "papermill": {
     "duration": 3.22246,
     "end_time": "2022-02-20T21:21:35.968827",
     "exception": false,
     "start_time": "2022-02-20T21:21:32.746367",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, Batch : 1, Running Loss : 2.3116092681884766\n",
      "Epoch : 100, Batch : 1, Running Loss : 6.623480203415966e-06\n",
      "Epoch : 200, Batch : 1, Running Loss : 3.6656642805610318e-06\n",
      "Epoch : 300, Batch : 1, Running Loss : 3.058451284232433e-06\n",
      "Epoch : 400, Batch : 1, Running Loss : 2.73062846645189e-06\n",
      "\n",
      "Accuracy for train: 0.20064724919093851\n",
      "Accuracy for validation: 0.2\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.07      0.06      0.07        47\n",
      "           1       0.07      0.19      0.11        16\n",
      "           2       0.19      0.12      0.15       123\n",
      "           3       0.35      0.22      0.27       126\n",
      "           4       0.30      0.21      0.24        58\n",
      "           5       0.05      0.07      0.06        29\n",
      "           6       0.49      0.36      0.41       106\n",
      "           7       0.05      0.05      0.05        37\n",
      "           8       0.11      0.42      0.17        26\n",
      "           9       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.20       575\n",
      "   macro avg       0.17      0.17      0.15       575\n",
      "weighted avg       0.26      0.20      0.21       575\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_features = next(iter(train_loader_beat_mel))[0].size()[1:]\n",
    "num_features = torch.tensor(num_features)\n",
    "net = Net(num_features = num_features)\n",
    "train_eval_model(500, net, './cnn_500_mel', 'loader_beat_mel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00a05d6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T21:21:36.048527Z",
     "iopub.status.busy": "2022-02-20T21:21:36.047487Z",
     "iopub.status.idle": "2022-02-20T21:21:41.836639Z",
     "shell.execute_reply": "2022-02-20T21:21:41.837397Z",
     "shell.execute_reply.started": "2022-02-20T21:07:03.199440Z"
    },
    "papermill": {
     "duration": 5.833255,
     "end_time": "2022-02-20T21:21:41.837638",
     "exception": false,
     "start_time": "2022-02-20T21:21:36.004383",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, Batch : 1, Running Loss : 2.324416399002075\n",
      "Epoch : 100, Batch : 1, Running Loss : 4.448131221579388e-05\n",
      "Epoch : 200, Batch : 1, Running Loss : 6.608616786252242e-06\n",
      "Epoch : 300, Batch : 1, Running Loss : 4.2803412725334056e-06\n",
      "Epoch : 400, Batch : 1, Running Loss : 3.360201844770927e-06\n",
      "Epoch : 500, Batch : 1, Running Loss : 2.3953568870638264e-06\n",
      "Epoch : 600, Batch : 1, Running Loss : 2.130862640115083e-06\n",
      "Epoch : 700, Batch : 1, Running Loss : 2.1308624127414078e-06\n",
      "Epoch : 800, Batch : 1, Running Loss : 2.1271373498166213e-06\n",
      "Epoch : 900, Batch : 1, Running Loss : 2.1308624127414078e-06\n",
      "\n",
      "Accuracy for train: 0.23171521035598705\n",
      "Accuracy for validation: 0.2118421052631579\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.08      0.10        63\n",
      "           1       0.00      0.00      0.00         3\n",
      "           2       0.09      0.29      0.13        24\n",
      "           3       0.26      0.17      0.20       126\n",
      "           4       0.33      0.22      0.27        58\n",
      "           5       0.00      0.00      0.00         2\n",
      "           6       0.62      0.33      0.43       147\n",
      "           7       0.03      0.04      0.03        28\n",
      "           8       0.10      0.20      0.13        50\n",
      "           9       0.44      0.20      0.28        74\n",
      "\n",
      "    accuracy                           0.21       575\n",
      "   macro avg       0.20      0.15      0.16       575\n",
      "weighted avg       0.33      0.21      0.25       575\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_features = next(iter(train_loader_beat_mel))[0].size()[1:]\n",
    "num_features = torch.tensor(num_features)\n",
    "net = Net(num_features = num_features)\n",
    "train_eval_model(1000, net, './cnn_1000_mel', 'loader_beat_mel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ecc9f6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T21:21:41.920332Z",
     "iopub.status.busy": "2022-02-20T21:21:41.919785Z",
     "iopub.status.idle": "2022-02-20T21:21:48.168410Z",
     "shell.execute_reply": "2022-02-20T21:21:48.169080Z",
     "shell.execute_reply.started": "2022-02-20T21:07:10.457518Z"
    },
    "papermill": {
     "duration": 6.292241,
     "end_time": "2022-02-20T21:21:48.169340",
     "exception": false,
     "start_time": "2022-02-20T21:21:41.877099",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, Batch : 1, Running Loss : 2.3134002685546875\n",
      "Epoch : 100, Batch : 1, Running Loss : 1.7519667380838655e-05\n",
      "Epoch : 200, Batch : 1, Running Loss : 1.1645114682323765e-05\n",
      "Epoch : 300, Batch : 1, Running Loss : 8.966693712864071e-06\n",
      "Epoch : 400, Batch : 1, Running Loss : 4.634238393919077e-06\n",
      "Epoch : 500, Batch : 1, Running Loss : 3.874287813232513e-06\n",
      "Epoch : 600, Batch : 1, Running Loss : 3.4980364489456406e-06\n",
      "Epoch : 700, Batch : 1, Running Loss : 3.252169108236558e-06\n",
      "Epoch : 800, Batch : 1, Running Loss : 3.1068834687175695e-06\n",
      "Epoch : 900, Batch : 1, Running Loss : 3.0398284707189305e-06\n",
      "\n",
      "Accuracy for train: 0.19676375404530744\n",
      "Accuracy for validation: 0.1763157894736842\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.12      0.12        42\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.03      0.06      0.03        36\n",
      "           3       0.09      0.13      0.11        53\n",
      "           4       0.15      0.13      0.14        47\n",
      "           5       0.12      0.10      0.11        52\n",
      "           6       0.67      0.25      0.36       212\n",
      "           7       0.15      0.10      0.12        60\n",
      "           8       0.01      0.10      0.02        10\n",
      "           9       0.21      0.11      0.14        63\n",
      "\n",
      "    accuracy                           0.16       575\n",
      "   macro avg       0.15      0.11      0.11       575\n",
      "weighted avg       0.33      0.16      0.20       575\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_features = next(iter(train_loader_beat_mel))[0].size()[1:]\n",
    "num_features = torch.tensor(num_features)\n",
    "net = Net(num_features = num_features)\n",
    "train_eval_model(1000, net, './cnn_1000_mel', 'loader_beat_mel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "73ee6d7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T21:21:48.257117Z",
     "iopub.status.busy": "2022-02-20T21:21:48.256337Z",
     "iopub.status.idle": "2022-02-20T21:21:51.468637Z",
     "shell.execute_reply": "2022-02-20T21:21:51.469288Z",
     "shell.execute_reply.started": "2022-02-20T21:07:17.955592Z"
    },
    "papermill": {
     "duration": 3.257992,
     "end_time": "2022-02-20T21:21:51.469584",
     "exception": false,
     "start_time": "2022-02-20T21:21:48.211592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, Batch : 1, Running Loss : 2.290799379348755\n",
      "Epoch : 100, Batch : 1, Running Loss : 2.602003405627329e-05\n",
      "Epoch : 200, Batch : 1, Running Loss : 4.991797140974086e-06\n",
      "Epoch : 300, Batch : 1, Running Loss : 2.6225884539599065e-06\n",
      "Epoch : 400, Batch : 1, Running Loss : 2.2202636955626076e-06\n",
      "\n",
      "Accuracy for train: 0.18576051779935276\n",
      "Accuracy for validation: 0.13289473684210526\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.03      0.12      0.04         8\n",
      "           1       0.03      0.50      0.05         2\n",
      "           2       0.30      0.16      0.21       146\n",
      "           3       0.17      0.16      0.17        85\n",
      "           4       0.10      0.20      0.13        20\n",
      "           5       0.15      0.11      0.13        55\n",
      "           6       0.23      0.19      0.21        94\n",
      "           7       0.17      0.13      0.15        54\n",
      "           8       0.09      0.24      0.13        37\n",
      "           9       0.12      0.05      0.07        74\n",
      "\n",
      "    accuracy                           0.15       575\n",
      "   macro avg       0.14      0.19      0.13       575\n",
      "weighted avg       0.20      0.15      0.16       575\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_features = next(iter(train_loader))[0].size()[1:]\n",
    "num_features = torch.tensor(num_features)\n",
    "net = Net(num_features = num_features)\n",
    "train_eval_model(500, net, './cnn_500_mel', 'loader')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a551c55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T21:21:51.559455Z",
     "iopub.status.busy": "2022-02-20T21:21:51.558630Z",
     "iopub.status.idle": "2022-02-20T21:21:57.671781Z",
     "shell.execute_reply": "2022-02-20T21:21:57.672446Z",
     "shell.execute_reply.started": "2022-02-20T21:07:21.685110Z"
    },
    "papermill": {
     "duration": 6.159592,
     "end_time": "2022-02-20T21:21:57.672679",
     "exception": false,
     "start_time": "2022-02-20T21:21:51.513087",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, Batch : 1, Running Loss : 2.294083595275879\n",
      "Epoch : 100, Batch : 1, Running Loss : 2.349482019781135e-05\n",
      "Epoch : 200, Batch : 1, Running Loss : 3.7290026284608757e-06\n",
      "Epoch : 300, Batch : 1, Running Loss : 2.346928795304848e-06\n",
      "Epoch : 400, Batch : 1, Running Loss : 2.201642928412184e-06\n",
      "Epoch : 500, Batch : 1, Running Loss : 2.2314452507998794e-06\n",
      "Epoch : 600, Batch : 1, Running Loss : 2.2612475731875747e-06\n",
      "Epoch : 700, Batch : 1, Running Loss : 2.2947749585000565e-06\n",
      "Epoch : 800, Batch : 1, Running Loss : 2.32085199058929e-06\n",
      "Epoch : 900, Batch : 1, Running Loss : 2.3432037323800614e-06\n",
      "\n",
      "Accuracy for train: 0.15210355987055016\n",
      "Accuracy for validation: 0.1368421052631579\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.06      0.07        69\n",
      "           1       0.05      0.09      0.06        22\n",
      "           2       0.12      0.11      0.12        92\n",
      "           3       0.16      0.19      0.17        70\n",
      "           4       0.23      0.10      0.13        94\n",
      "           5       0.00      0.00      0.00        21\n",
      "           6       0.08      0.25      0.12        24\n",
      "           7       0.17      0.12      0.14        59\n",
      "           8       0.19      0.21      0.20        96\n",
      "           9       0.06      0.07      0.06        28\n",
      "\n",
      "    accuracy                           0.13       575\n",
      "   macro avg       0.12      0.12      0.11       575\n",
      "weighted avg       0.15      0.13      0.13       575\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_features = next(iter(train_loader))[0].size()[1:]\n",
    "num_features = torch.tensor(num_features)\n",
    "net = Net(num_features = num_features)\n",
    "train_eval_model(1000, net, './cnn_1000_mel', 'loader')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6dfc3e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T21:21:57.777323Z",
     "iopub.status.busy": "2022-02-20T21:21:57.772419Z",
     "iopub.status.idle": "2022-02-20T21:23:34.039900Z",
     "shell.execute_reply": "2022-02-20T21:23:34.040377Z",
     "shell.execute_reply.started": "2022-02-20T21:07:29.091586Z"
    },
    "papermill": {
     "duration": 96.318101,
     "end_time": "2022-02-20T21:23:34.040575",
     "exception": false,
     "start_time": "2022-02-20T21:21:57.722474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, Batch : 1, Running Loss : 0.5177009293822996\n",
      "Epoch : 100, Batch : 1, Running Loss : 0.017175129599321007\n",
      "Epoch : 200, Batch : 1, Running Loss : 0.012150694145091102\n",
      "Epoch : 300, Batch : 1, Running Loss : 0.0062951936208391155\n",
      "Epoch : 400, Batch : 1, Running Loss : 0.002192753682042879\n",
      "Epoch : 500, Batch : 1, Running Loss : 0.0012385864615462555\n",
      "Epoch : 600, Batch : 1, Running Loss : 0.0010145326441170057\n",
      "Epoch : 700, Batch : 1, Running Loss : 0.0009414444356843296\n",
      "Epoch : 800, Batch : 1, Running Loss : 0.0009016567307501995\n",
      "Epoch : 900, Batch : 1, Running Loss : 0.001020063254727234\n",
      "-0.6001243274285459\n"
     ]
    }
   ],
   "source": [
    "directory_multitask = '../input/patreco3-multitask-affective-music/data/multitask_dataset'\n",
    "train_multitask = SpectrogramDataset(directory_multitask, train = True, read_spec = read_spectrogram, chroma = False)\n",
    "train_multitask, val_multitask = torch_train_val_split(train_multitask, 32, 32, val_size = .33)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "num_mel = 128\n",
    "num_chroma = 12\n",
    "\n",
    "lstm = BasicLSTM(num_mel, 64, 1, 1)\n",
    "lstm.double()\n",
    "lstm.to(DEVICE)\n",
    "\n",
    "first_input = next(iter(train_multitask))[0]\n",
    "num_features = first_input.size()[1:]\n",
    "num_features = torch.tensor(num_features)\n",
    "\n",
    "loss_function = nn.MSELoss().to(DEVICE)\n",
    "optimizer_lstm = torch.optim.Adam(lstm.parameters(), lr=0.001,  weight_decay=1e-5)\n",
    "\n",
    "lstm.fit(1000, train_multitask, loss_function, optimizer_lstm, './sentiment_mel_best_lstm', batch_overfit=True)\n",
    "y_pred, y_true = lstm.evaluate(val_multitask, loss_function)\n",
    "\n",
    "print(r2_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9382765d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T21:23:34.147032Z",
     "iopub.status.busy": "2022-02-20T21:23:34.145698Z",
     "iopub.status.idle": "2022-02-20T21:23:36.330002Z",
     "shell.execute_reply": "2022-02-20T21:23:36.330502Z",
     "shell.execute_reply.started": "2022-02-20T21:09:06.260158Z"
    },
    "papermill": {
     "duration": 2.23981,
     "end_time": "2022-02-20T21:23:36.330715",
     "exception": false,
     "start_time": "2022-02-20T21:23:34.090905",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.4457510838324761"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_train, y_true_train = lstm.evaluate(train_multitask, loss_function)\n",
    "r2_score(y_true_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "99545697",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T21:23:36.444725Z",
     "iopub.status.busy": "2022-02-20T21:23:36.444169Z",
     "iopub.status.idle": "2022-02-20T21:24:55.030975Z",
     "shell.execute_reply": "2022-02-20T21:24:55.031391Z",
     "shell.execute_reply.started": "2022-02-20T21:09:08.736382Z"
    },
    "papermill": {
     "duration": 78.644376,
     "end_time": "2022-02-20T21:24:55.031575",
     "exception": false,
     "start_time": "2022-02-20T21:23:36.387199",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, Batch : 1, Running Loss : 0.1809661908095553\n",
      "Epoch : 100, Batch : 1, Running Loss : 0.002960557802679402\n",
      "Epoch : 200, Batch : 1, Running Loss : 0.004594220829668826\n",
      "Epoch : 300, Batch : 1, Running Loss : 0.002019956718756071\n",
      "Epoch : 400, Batch : 1, Running Loss : 0.001257799322731224\n",
      "Epoch : 500, Batch : 1, Running Loss : 0.0017755437710587246\n",
      "Epoch : 600, Batch : 1, Running Loss : 0.0013707764797101568\n",
      "Epoch : 700, Batch : 1, Running Loss : 0.0016532554727344121\n",
      "Epoch : 800, Batch : 1, Running Loss : 0.0009978675272008194\n",
      "Epoch : 900, Batch : 1, Running Loss : 0.0009142716316724683\n",
      "-0.23564865200224494\n"
     ]
    }
   ],
   "source": [
    "directory_multitask = '../input/patreco3-multitask-affective-music/data/multitask_dataset'\n",
    "train_multitask = SpectrogramDataset(directory_multitask, train = True, read_spec = read_spectrogram, chroma = False, label_index=2)\n",
    "train_multitask, val_multitask = torch_train_val_split(train_multitask, 32, 32, val_size = .33)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "num_mel = 128\n",
    "num_chroma = 12\n",
    "\n",
    "lstm = BasicLSTM(num_mel, 64, 1, 1)\n",
    "lstm.double()\n",
    "lstm.to(DEVICE)\n",
    "\n",
    "first_input = next(iter(train_multitask))[0]\n",
    "num_features = first_input.size()[1:]\n",
    "num_features = torch.tensor(num_features)\n",
    "\n",
    "loss_function = nn.MSELoss().to(DEVICE)\n",
    "optimizer_lstm = torch.optim.Adam(lstm.parameters(), lr=0.001,  weight_decay=1e-5)\n",
    "\n",
    "lstm.fit(1000, train_multitask, loss_function, optimizer_lstm, './sentiment_mel_best_lstm', batch_overfit=True)\n",
    "y_pred, y_true = lstm.evaluate(val_multitask, loss_function)\n",
    "\n",
    "print(r2_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2cb88a85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T21:24:55.142975Z",
     "iopub.status.busy": "2022-02-20T21:24:55.141760Z",
     "iopub.status.idle": "2022-02-20T21:24:56.609843Z",
     "shell.execute_reply": "2022-02-20T21:24:56.609378Z",
     "shell.execute_reply.started": "2022-02-20T21:10:30.427286Z"
    },
    "papermill": {
     "duration": 1.526498,
     "end_time": "2022-02-20T21:24:56.609977",
     "exception": false,
     "start_time": "2022-02-20T21:24:55.083479",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.15512642381352615"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_train, y_true_train = lstm.evaluate(train_multitask, loss_function)\n",
    "r2_score(y_true_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d058e9a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T21:24:56.721479Z",
     "iopub.status.busy": "2022-02-20T21:24:56.720878Z",
     "iopub.status.idle": "2022-02-20T21:26:14.671978Z",
     "shell.execute_reply": "2022-02-20T21:26:14.672399Z",
     "shell.execute_reply.started": "2022-02-20T21:10:31.918761Z"
    },
    "papermill": {
     "duration": 78.010149,
     "end_time": "2022-02-20T21:26:14.672585",
     "exception": false,
     "start_time": "2022-02-20T21:24:56.662436",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, Batch : 1, Running Loss : 1.0159484593085393\n",
      "Epoch : 100, Batch : 1, Running Loss : 0.007556597692716099\n",
      "Epoch : 200, Batch : 1, Running Loss : 0.008346195324199708\n",
      "Epoch : 300, Batch : 1, Running Loss : 0.034529539877767815\n",
      "Epoch : 400, Batch : 1, Running Loss : 0.02229578403335255\n",
      "Epoch : 500, Batch : 1, Running Loss : 0.00596227892462008\n",
      "Epoch : 600, Batch : 1, Running Loss : 0.015058994210324535\n",
      "Epoch : 700, Batch : 1, Running Loss : 0.014067949026860479\n",
      "Epoch : 800, Batch : 1, Running Loss : 0.013165438658718854\n",
      "Epoch : 900, Batch : 1, Running Loss : 0.012605598742187009\n",
      "-0.14811675919150247\n"
     ]
    }
   ],
   "source": [
    "directory_multitask = '../input/patreco3-multitask-affective-music/data/multitask_dataset'\n",
    "train_multitask = SpectrogramDataset(directory_multitask, train = True, read_spec = read_spectrogram, chroma = False, label_index=3)\n",
    "train_multitask, val_multitask = torch_train_val_split(train_multitask, 32, 32, val_size = .33)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "num_mel = 128\n",
    "num_chroma = 12\n",
    "\n",
    "lstm = BasicLSTM(num_mel, 64, 1, 1)\n",
    "lstm.double()\n",
    "lstm.to(DEVICE)\n",
    "\n",
    "first_input = next(iter(train_multitask))[0]\n",
    "num_features = first_input.size()[1:]\n",
    "num_features = torch.tensor(num_features)\n",
    "\n",
    "loss_function = nn.MSELoss().to(DEVICE)\n",
    "optimizer_lstm = torch.optim.Adam(lstm.parameters(), lr=0.001,  weight_decay=1e-5)\n",
    "\n",
    "lstm.fit(1000, train_multitask, loss_function, optimizer_lstm, './sentiment_mel_best_lstm', batch_overfit=True)\n",
    "y_pred, y_true = lstm.evaluate(val_multitask, loss_function)\n",
    "\n",
    "print(r2_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7bc80306",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T21:26:14.784038Z",
     "iopub.status.busy": "2022-02-20T21:26:14.783388Z",
     "iopub.status.idle": "2022-02-20T21:26:16.255640Z",
     "shell.execute_reply": "2022-02-20T21:26:16.255188Z",
     "shell.execute_reply.started": "2022-02-20T21:12:03.913706Z"
    },
    "papermill": {
     "duration": 1.52884,
     "end_time": "2022-02-20T21:26:16.255773",
     "exception": false,
     "start_time": "2022-02-20T21:26:14.726933",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.08359513800924545"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_train, y_true_train = lstm.evaluate(train_multitask, loss_function)\n",
    "r2_score(y_true_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eb3dfcda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T21:26:16.370345Z",
     "iopub.status.busy": "2022-02-20T21:26:16.369479Z",
     "iopub.status.idle": "2022-02-20T21:26:16.372353Z",
     "shell.execute_reply": "2022-02-20T21:26:16.372760Z"
    },
    "papermill": {
     "duration": 0.061896,
     "end_time": "2022-02-20T21:26:16.372899",
     "exception": false,
     "start_time": "2022-02-20T21:26:16.311003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"directory_multitask = '../input/patreco3-multitask-affective-music/data/multitask_dataset'\\ntrain_multitask = SpectrogramDataset(directory_multitask, train = True, read_spec = read_spectrogram, chroma = False)\\ntrain_multitask, val_multitask = torch_train_val_split(train_multitask, 32, 32, val_size = .33)\\n\\ncnn = Net(num_features, output_size = 1)\\ncnn.double()\\ncnn.to(DEVICE)\\noptimizer_net = torch.optim.Adam(cnn.parameters(), lr=0.001,  weight_decay=1e-5)\\n\\ncnn.fit(1000, train_multitask, loss_function, optimizer_net, './sentiment_mel_best_cnn')\\ny_pred, y_true = cnn.evaluate(val_multitask, loss_function)\\n\\nprint(r2_score(y_true, y_pred))\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''directory_multitask = '../input/patreco3-multitask-affective-music/data/multitask_dataset'\n",
    "train_multitask = SpectrogramDataset(directory_multitask, train = True, read_spec = read_spectrogram, chroma = False)\n",
    "train_multitask, val_multitask = torch_train_val_split(train_multitask, 32, 32, val_size = .33)\n",
    "\n",
    "cnn = Net(num_features, output_size = 1)\n",
    "cnn.double()\n",
    "cnn.to(DEVICE)\n",
    "optimizer_net = torch.optim.Adam(cnn.parameters(), lr=0.001,  weight_decay=1e-5)\n",
    "\n",
    "cnn.fit(1000, train_multitask, loss_function, optimizer_net, './sentiment_mel_best_cnn')\n",
    "y_pred, y_true = cnn.evaluate(val_multitask, loss_function)\n",
    "\n",
    "print(r2_score(y_true, y_pred))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9305863b",
   "metadata": {
    "_cell_guid": "4d7d7e28-186a-4e40-97d2-5a0e11497c8a",
    "_uuid": "dc24bb61-aaee-4b47-99d0-e483a0504efa",
    "execution": {
     "iopub.execute_input": "2022-02-20T21:26:16.504486Z",
     "iopub.status.busy": "2022-02-20T21:26:16.503403Z",
     "iopub.status.idle": "2022-02-20T21:26:16.507137Z",
     "shell.execute_reply": "2022-02-20T21:26:16.507548Z"
    },
    "papermill": {
     "duration": 0.080295,
     "end_time": "2022-02-20T21:26:16.507681",
     "exception": false,
     "start_time": "2022-02-20T21:26:16.427386",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'if __name__ == \\'__main__\\': \\n\\n    # %% [code] {\"execution\":{\"iopub.status.busy\":\"2022-02-08T06:50:41.886063Z\",\"iopub.execute_input\":\"2022-02-08T06:50:41.886368Z\",\"iopub.status.idle\":\"2022-02-08T06:50:42.818285Z\",\"shell.execute_reply.started\":\"2022-02-08T06:50:41.886332Z\",\"shell.execute_reply\":\"2022-02-08T06:50:42.817544Z\"}}\\n    directory = \\'../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms/train_labels.txt\\'\\n    train_data = pd.read_csv(directory, sep = \\'\\t\\')\\n    number_samples = train_data.shape[0]\\n    sample_rows = np.random.randint(number_samples, size = 2)\\n\\n    while train_data.iloc[sample_rows[0]][1] == train_data.iloc[sample_rows[1]][1]:\\n\\n        sample_rows[1] = np.random.randint(number_samples)\\n\\n    directory = \\'../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms/train/\\'\\n    samples = [train_data.iloc[elem][0] for elem in sample_rows]\\n    genre = [train_data.iloc[elem][1] for elem in sample_rows]\\n\\n    samples = [elem.split(\\'.gz\\')[0] for elem in samples]\\n\\n    fig = plt.figure(figsize = (10, 10))\\n    spectrograms = []\\n    for i in range(len(samples)):\\n\\n        filename = os.path.join(directory, samples[i])\\n        ax = fig.add_subplot(2, 1, i + 1)\\n        ax.set_xlabel(\\'Time\\')\\n        ax.set_ylabel(\\'Frequency\\')\\n\\n        spectrogram = np.load(filename)[:128]\\n        spectrograms.append(spectrogram)\\n        print(f\\'Spectrogram time steps: {spectrogram.shape[1]}\\')\\n\\n        img = librosa.display.specshow(spectrogram, x_axis = \\'time\\', y_axis = \\'mel\\')\\n\\n        fig.colorbar(img, ax=ax, format =\\'% +2.f dB\\')\\n        ax.set(title=\\'Spectrogram for {}\\'.format(genre[i]))\\n\\n    # %% [markdown]\\n    # These spectrograms describe the amplitude (dB) as a function of time and frequency.\\n\\n    # %% [markdown]\\n    # The time steps for the two spectrograms are 1291, 1293 respectively. These numbers are too large for an LSTM to perform well. Therefore we will use beat synced spectrograms instead.\\n\\n    # %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2022-02-08T06:50:42.820199Z\",\"iopub.execute_input\":\"2022-02-08T06:50:42.820973Z\",\"iopub.status.idle\":\"2022-02-08T06:50:43.366178Z\",\"shell.execute_reply.started\":\"2022-02-08T06:50:42.820927Z\",\"shell.execute_reply\":\"2022-02-08T06:50:43.365521Z\"}}\\n    directory = \\'../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms_beat/train\\'\\n\\n    fig = plt.figure(figsize = (10, 10))\\n    spectrograms = []\\n    for i in range(len(samples)):\\n\\n        filename = os.path.join(directory, samples[i])\\n        ax = fig.add_subplot(2, 1, i + 1)\\n        ax.set_xlabel(\\'Time\\')\\n        ax.set_ylabel(\\'Frequency\\')\\n\\n        spectrogram = np.load(filename)[:128]\\n        spectrograms.append(spectrogram)\\n        print(f\\'Spectrogram time steps: {spectrogram.shape[1]}\\')\\n\\n        img = librosa.display.specshow(spectrogram, x_axis = \\'time\\', y_axis=\\'mel\\')\\n\\n        fig.colorbar(img, ax=ax, format =\\'% +2.f dB\\')\\n        ax.set(title=\\'Spectrogram for {}\\'.format(genre[i]))\\n\\n    # %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2022-02-08T06:50:43.367514Z\",\"iopub.execute_input\":\"2022-02-08T06:50:43.368272Z\",\"iopub.status.idle\":\"2022-02-08T06:50:43.887186Z\",\"shell.execute_reply.started\":\"2022-02-08T06:50:43.368232Z\",\"shell.execute_reply\":\"2022-02-08T06:50:43.886500Z\"}}\\n    directory = \\'../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms/train/\\'\\n    fig = plt.figure(figsize = (10, 10))\\n    spectrograms = []\\n    for i in range(len(samples)):\\n\\n        filename = os.path.join(directory, samples[i])\\n        ax = fig.add_subplot(2, 1, i + 1)\\n        ax.set_xlabel(\\'Time\\')\\n        ax.set_ylabel(\\'Frequency\\')\\n\\n        spectrogram = np.load(filename)[128:]\\n        spectrograms.append(spectrogram)\\n        print(f\\'Spectrogram time steps: {spectrogram.shape[1]}\\')\\n\\n        img = librosa.display.specshow(spectrogram, x_axis = \\'time\\', y_axis = \\'mel\\')\\n\\n        fig.colorbar(img, ax=ax, format =\\'% +.2f dB\\')\\n        ax.set(title=\\'Chromogram for {}\\'.format(genre[i]))\\n\\n    # %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2022-02-08T06:50:43.888514Z\",\"iopub.execute_input\":\"2022-02-08T06:50:43.889314Z\",\"iopub.status.idle\":\"2022-02-08T06:50:44.374974Z\",\"shell.execute_reply.started\":\"2022-02-08T06:50:43.889273Z\",\"shell.execute_reply\":\"2022-02-08T06:50:44.374299Z\"}}\\n    directory = \\'../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms_beat/train\\'\\n\\n    fig = plt.figure(figsize = (10, 10))\\n    spectrograms = []\\n    for i in range(len(samples)):\\n\\n        filename = os.path.join(directory, samples[i])\\n        ax = fig.add_subplot(2, 1, i + 1)\\n        ax.set_xlabel(\\'Time\\')\\n        ax.set_ylabel(\\'Frequency\\')\\n\\n        spectrogram = np.load(filename)[128:]\\n        spectrograms.append(spectrogram)\\n        print(f\\'Spectrogram time steps: {spectrogram.shape[1]}\\')\\n\\n        img = librosa.display.specshow(spectrogram, x_axis = \\'time\\', y_axis=\\'mel\\')\\n\\n        fig.colorbar(img, ax=ax, format =\\'% +.2f dB\\')\\n        ax.set(title=\\'Chromogram for {}\\'.format(genre[i]))\\n\\n    # %% [markdown]\\n    # Map similar classes together ignore underrepresented classes.\\n\\n    # %% [code] {\"execution\":{\"iopub.status.busy\":\"2022-02-08T06:50:44.376147Z\",\"iopub.execute_input\":\"2022-02-08T06:50:44.376939Z\",\"iopub.status.idle\":\"2022-02-08T06:50:44.385017Z\",\"shell.execute_reply.started\":\"2022-02-08T06:50:44.376897Z\",\"shell.execute_reply\":\"2022-02-08T06:50:44.384237Z\"}}\\n    import copy\\n    import os\\n\\n    import numpy as np\\n    from sklearn.preprocessing import LabelEncoder\\n    from torch.utils.data import DataLoader, Dataset, SubsetRandomSampler\\n\\n\\n    # %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2022-02-08T06:50:44.544403Z\",\"iopub.execute_input\":\"2022-02-08T06:50:44.544836Z\",\"iopub.status.idle\":\"2022-02-08T06:51:32.858293Z\",\"shell.execute_reply.started\":\"2022-02-08T06:50:44.544639Z\",\"shell.execute_reply\":\"2022-02-08T06:51:32.853793Z\"}}\\n    directory = \\'../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms/\\'\\n\\n    train_loader_mel, val_loader_mel, test_loader_mel = train_test_val_splitter(directory)\\n\\n    # %% [code] {\"execution\":{\"iopub.status.busy\":\"2022-02-08T06:51:32.862310Z\",\"iopub.execute_input\":\"2022-02-08T06:51:32.863718Z\",\"iopub.status.idle\":\"2022-02-08T06:51:44.964878Z\",\"shell.execute_reply.started\":\"2022-02-08T06:51:32.863661Z\",\"shell.execute_reply\":\"2022-02-08T06:51:44.964106Z\"},\"jupyter\":{\"outputs_hidden\":false}}\\n    directory_beat = \\'../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms_beat/\\'\\n\\n    train_loader_beat_mel, val_loader_beat_mel, test_loader_beat_mel = train_test_val_splitter(directory_beat)\\n\\n    # %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2022-02-08T06:51:44.966153Z\",\"iopub.execute_input\":\"2022-02-08T06:51:44.966414Z\",\"iopub.status.idle\":\"2022-02-08T06:51:47.544861Z\",\"shell.execute_reply.started\":\"2022-02-08T06:51:44.966381Z\",\"shell.execute_reply\":\"2022-02-08T06:51:47.544106Z\"}}\\n    directory_beat = \\'../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms_beat/\\'\\n\\n    train_loader_beat_chroma, val_loader_beat_chroma, test_loader_beat_chroma = train_test_val_splitter(directory_beat, chroma = True)\\n\\n    # %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2022-02-08T06:51:47.546239Z\",\"iopub.execute_input\":\"2022-02-08T06:51:47.546510Z\",\"iopub.status.idle\":\"2022-02-08T06:51:49.961608Z\",\"shell.execute_reply.started\":\"2022-02-08T06:51:47.546473Z\",\"shell.execute_reply\":\"2022-02-08T06:51:49.960847Z\"}}\\n    train_loader, val_loader, test_loader = train_test_val_splitter(directory_beat, fused = True)\\n\\n    # %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2022-02-08T06:51:49.962820Z\",\"iopub.execute_input\":\"2022-02-08T06:51:49.965991Z\",\"iopub.status.idle\":\"2022-02-08T06:51:57.477460Z\",\"shell.execute_reply.started\":\"2022-02-08T06:51:49.965950Z\",\"shell.execute_reply\":\"2022-02-08T06:51:57.476752Z\"}}\\n    beat_mel_specs_nomap = SpectrogramDataset(\\n         directory_beat,\\n         train=True,\\n         max_length=-1,\\n         read_spec=read_spectrogram,\\n         chroma = False)\\n\\n    labels_before = []\\n    for i in range(len(beat_mel_specs_nomap)):\\n        _, label, _ = beat_mel_specs_nomap[i]\\n        labels_before.append(label)\\n\\n    beat_mel_specs = SpectrogramDataset(\\n         directory_beat,\\n         train=True,\\n         max_length=-1,\\n         class_mapping = class_mapping,\\n         read_spec=read_spectrogram,\\n         chroma = False)\\n\\n    labels_after = []\\n    for i in range(len(beat_mel_specs)):\\n        _, label, _ = beat_mel_specs[i]\\n        labels_after.append(label)\\n\\n    # %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2022-02-08T06:51:57.478617Z\",\"iopub.execute_input\":\"2022-02-08T06:51:57.480071Z\",\"iopub.status.idle\":\"2022-02-08T06:51:57.494731Z\",\"shell.execute_reply.started\":\"2022-02-08T06:51:57.480031Z\",\"shell.execute_reply\":\"2022-02-08T06:51:57.494079Z\"}}\\n    datasets = {\\n    \\'train_loader_mel\\': train_loader_mel,\\n    \\'train_loader_beat_mel\\': train_loader_beat_mel,\\n    \\'train_loader_beat_chroma\\': train_loader_beat_chroma,\\n    \\'train_loader\\': train_loader,\\n    \\'test_loader_mel\\': test_loader_mel,\\n    \\'test_loader_beat_mel\\': test_loader_beat_mel,\\n    \\'test_loader_beat_chroma\\': test_loader_beat_chroma,\\n    \\'test_loader\\': test_loader,\\n    \\'val_loader_mel\\': val_loader_mel,\\n    \\'val_loader_beat_mel\\': val_loader_beat_mel,\\n    \\'val_loader_beat_chroma\\': val_loader_beat_chroma,\\n    \\'val_loader\\': val_loader}\\n\\n    # %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2022-02-08T06:51:57.496406Z\",\"iopub.execute_input\":\"2022-02-08T06:51:57.496674Z\",\"iopub.status.idle\":\"2022-02-08T06:51:57.893288Z\",\"shell.execute_reply.started\":\"2022-02-08T06:51:57.496639Z\",\"shell.execute_reply\":\"2022-02-08T06:51:57.892588Z\"}}\\n    fig = plt.figure(figsize = (10, 10))\\n    ax = fig.add_subplot(2, 1, 1)\\n\\n    ax.hist(labels_before)\\n    ax.set_title(\\'Before Mapping\\')\\n\\n    ax = fig.add_subplot(2, 1, 2)\\n\\n    ax.hist(labels_after)\\n    ax.set_title(\\'After Mapping\\')\\n\\n    # %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2022-02-08T06:51:57.894677Z\",\"iopub.execute_input\":\"2022-02-08T06:51:57.895758Z\",\"iopub.status.idle\":\"2022-02-08T06:51:57.900074Z\",\"shell.execute_reply.started\":\"2022-02-08T06:51:57.895433Z\",\"shell.execute_reply\":\"2022-02-08T06:51:57.899271Z\"}}\\n    # Define useful parameters that are the same for all the models.\\n    num_mel = 128\\n    num_chroma = 12\\n    n_classes = 10\\n\\n    # %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2022-02-08T06:51:57.901419Z\",\"iopub.execute_input\":\"2022-02-08T06:51:57.902290Z\",\"iopub.status.idle\":\"2022-02-08T06:52:17.971310Z\",\"shell.execute_reply.started\":\"2022-02-08T06:51:57.902251Z\",\"shell.execute_reply\":\"2022-02-08T06:52:17.970564Z\"}}\\n    RNN_SIZE = 32\\n    EPOCHS = 2000\\n    model = BasicLSTM(num_mel, RNN_SIZE, n_classes, 1, bidirectional=True)\\n    loss_function = nn.CrossEntropyLoss()\\n    optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\\n\\n    DEVICE = torch.device(\\'cuda\\')\\n\\n    model.double()\\n    model.to(DEVICE)\\n\\n    train_dataset(EPOCHS, train_loader_beat_mel, model, loss_function, optimizer, batch_overfit = True, model_name = \\'./overfit_model\\')\\n\\n    # %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2022-02-08T06:52:17.972685Z\",\"iopub.execute_input\":\"2022-02-08T06:52:17.973089Z\",\"iopub.status.idle\":\"2022-02-08T06:53:09.472187Z\",\"shell.execute_reply.started\":\"2022-02-08T06:52:17.973050Z\",\"shell.execute_reply\":\"2022-02-08T06:53:09.471012Z\"}}\\n    model = BasicLSTM(num_mel, 32, 10, 1, bidirectional=True)\\n    train_eval_model(500, model, \\'./mel_32_500\\', \\'loader_mel\\')\\n\\n    # %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2022-02-08T06:53:09.473892Z\",\"iopub.execute_input\":\"2022-02-08T06:53:09.474163Z\",\"iopub.status.idle\":\"2022-02-08T06:54:51.458511Z\",\"shell.execute_reply.started\":\"2022-02-08T06:53:09.474126Z\",\"shell.execute_reply\":\"2022-02-08T06:54:51.457765Z\"}}\\n    model = BasicLSTM(num_mel, 64, 10, 1, bidirectional=True)\\n    train_eval_model(1000, model, \\'./mel_64_1000\\', \\'loader_mel\\')\\n\\n    # %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2022-02-08T06:54:51.460139Z\",\"iopub.execute_input\":\"2022-02-08T06:54:51.460661Z\",\"iopub.status.idle\":\"2022-02-08T06:54:56.913416Z\",\"shell.execute_reply.started\":\"2022-02-08T06:54:51.460621Z\",\"shell.execute_reply\":\"2022-02-08T06:54:56.912717Z\"}}\\n    model = BasicLSTM(num_mel, 32, 10, 1, bidirectional=True)\\n    train_eval_model(500,model, \\'./beat_mel_32_500\\', \\'loader_beat_mel\\')\\n\\n    # %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2022-02-08T06:54:56.914795Z\",\"iopub.execute_input\":\"2022-02-08T06:54:56.915622Z\",\"iopub.status.idle\":\"2022-02-08T06:55:08.681901Z\",\"shell.execute_reply.started\":\"2022-02-08T06:54:56.915584Z\",\"shell.execute_reply\":\"2022-02-08T06:55:08.681046Z\"}}\\n    model = BasicLSTM(num_mel, 64, 10, 1, bidirectional=True)\\n    train_eval_model(1000, model, \\'./beat_mel_64_1000\\', \\'loader_beat_mel\\')\\n\\n    # %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2022-02-08T06:55:08.683129Z\",\"iopub.execute_input\":\"2022-02-08T06:55:08.685875Z\",\"iopub.status.idle\":\"2022-02-08T06:55:13.779169Z\",\"shell.execute_reply.started\":\"2022-02-08T06:55:08.685831Z\",\"shell.execute_reply\":\"2022-02-08T06:55:13.777692Z\"}}\\n    model = BasicLSTM(num_chroma, 32, 10, 1, bidirectional=True)\\n    train_eval_model(500, model, \\'./beat_chroma_32_500\\', \\'loader_beat_chroma\\')\\n\\n    # %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2022-02-08T06:55:13.780615Z\",\"iopub.execute_input\":\"2022-02-08T06:55:13.780882Z\",\"iopub.status.idle\":\"2022-02-08T06:55:24.514526Z\",\"shell.execute_reply.started\":\"2022-02-08T06:55:13.780845Z\",\"shell.execute_reply\":\"2022-02-08T06:55:24.513786Z\"}}\\n    model = BasicLSTM(num_chroma, 64, 10, 1, bidirectional=True)\\n    train_eval_model(1000, model, \\'./beat_chroma_64_1000\\', \\'loader_beat_chroma\\')\\n\\n    # %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2022-02-08T06:55:24.515658Z\",\"iopub.execute_input\":\"2022-02-08T06:55:24.516057Z\",\"iopub.status.idle\":\"2022-02-08T06:55:30.083081Z\",\"shell.execute_reply.started\":\"2022-02-08T06:55:24.516020Z\",\"shell.execute_reply\":\"2022-02-08T06:55:30.082310Z\"}}\\n    model = BasicLSTM(num_chroma + num_mel, 32, 10, 1, bidirectional=True)\\n    train_eval_model(500, model, \\'./fused_32_500\\', \\'loader\\')\\n\\n    # %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2022-02-08T06:55:30.100806Z\",\"iopub.execute_input\":\"2022-02-08T06:55:30.101138Z\",\"iopub.status.idle\":\"2022-02-08T06:55:30.111431Z\",\"shell.execute_reply.started\":\"2022-02-08T06:55:30.101096Z\",\"shell.execute_reply\":\"2022-02-08T06:55:30.110574Z\"}}\\n    model = net\\n    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\\n    model.double()\\n    model.to(DEVICE)\\n    loss_function = nn.CrossEntropyLoss().to(DEVICE)\\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5).to(DEVICE)\\n    EPOCHS = np.linspace(500, 1500, 3)\\n\\n    # %% [markdown]\\n    # # MNIST ConvNetJS \\n    # The model trained has the following layers:\\n    # * 2 Convolution layers with a ReLU activation function, stride = 1, pad = 2, num_filters = 8, 16 respectively.\\n    # * 2 Pool Layers with max pooling, stride = 2, stride = 3\\n    # * FC layer with softmax activation\\n    # \\n    # \\n    # ## Convolution Layer: \\n    # This layer is used to filter the image by applying learnable weights to a subset of the inout matrix.\\n    # In this model the first layer uses 6 5 by 5 filters and the second 16 5 by 5 filters. By filtering the image we achieve a form of feature selection from the initial image. The end result for every filter is called feature map, as it maps the initial image to some of its significant features. After that we use ReLU.\\n    # \\n    # ## ReLU activation function:\\n    # The convolution operator used above is a linear operator. While useful for feature selection, real data exhibit great nonlinearity. Therefore we need to add some form of nonlinearity to our model, which is what ReLU accomplises.\\n    # \\n    # ## Pool Layer:\\n    # Pooling or specifically max pooling selects the biggest value inside in a spatial area defined by pooling size. In our case we use 8 2 by 2 matrices in the pooling layer. The main utilities of pooling are:\\n    # \\n    # * Decreasing the number of parameters and computations making the model manageable and controlling overfitting.\\n    # * Makes the model invariant to small variations in the input data.\\n    # \\n    # ## Fully Connected Layer:\\n    # This layer is basically an MLP with the use of a softmax activation function in the end.\\n    # The purpose of this layer is to classify the image shown in a specifc digit (0-9).\\n    # The output from the convolution and pooling layer represents high-level features which are then used by the fully connected layer to predict the digit shown.\\n\\n    # %% [code] {\"jupyter\":{\"outputs_hidden\":false}}'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''if __name__ == '__main__': \n",
    "\n",
    "    # %% [code] {\"execution\":{\"iopub.status.busy\":\"2022-02-08T06:50:41.886063Z\",\"iopub.execute_input\":\"2022-02-08T06:50:41.886368Z\",\"iopub.status.idle\":\"2022-02-08T06:50:42.818285Z\",\"shell.execute_reply.started\":\"2022-02-08T06:50:41.886332Z\",\"shell.execute_reply\":\"2022-02-08T06:50:42.817544Z\"}}\n",
    "    directory = '../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms/train_labels.txt'\n",
    "    train_data = pd.read_csv(directory, sep = '\\t')\n",
    "    number_samples = train_data.shape[0]\n",
    "    sample_rows = np.random.randint(number_samples, size = 2)\n",
    "\n",
    "    while train_data.iloc[sample_rows[0]][1] == train_data.iloc[sample_rows[1]][1]:\n",
    "\n",
    "        sample_rows[1] = np.random.randint(number_samples)\n",
    "\n",
    "    directory = '../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms/train/'\n",
    "    samples = [train_data.iloc[elem][0] for elem in sample_rows]\n",
    "    genre = [train_data.iloc[elem][1] for elem in sample_rows]\n",
    "\n",
    "    samples = [elem.split('.gz')[0] for elem in samples]\n",
    "\n",
    "    fig = plt.figure(figsize = (10, 10))\n",
    "    spectrograms = []\n",
    "    for i in range(len(samples)):\n",
    "\n",
    "        filename = os.path.join(directory, samples[i])\n",
    "        ax = fig.add_subplot(2, 1, i + 1)\n",
    "        ax.set_xlabel('Time')\n",
    "        ax.set_ylabel('Frequency')\n",
    "\n",
    "        spectrogram = np.load(filename)[:128]\n",
    "        spectrograms.append(spectrogram)\n",
    "        print(f'Spectrogram time steps: {spectrogram.shape[1]}')\n",
    "\n",
    "        img = librosa.display.specshow(spectrogram, x_axis = 'time', y_axis = 'mel')\n",
    "\n",
    "        fig.colorbar(img, ax=ax, format ='% +2.f dB')\n",
    "        ax.set(title='Spectrogram for {}'.format(genre[i]))\n",
    "\n",
    "    # %% [markdown]\n",
    "    # These spectrograms describe the amplitude (dB) as a function of time and frequency.\n",
    "\n",
    "    # %% [markdown]\n",
    "    # The time steps for the two spectrograms are 1291, 1293 respectively. These numbers are too large for an LSTM to perform well. Therefore we will use beat synced spectrograms instead.\n",
    "\n",
    "    # %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2022-02-08T06:50:42.820199Z\",\"iopub.execute_input\":\"2022-02-08T06:50:42.820973Z\",\"iopub.status.idle\":\"2022-02-08T06:50:43.366178Z\",\"shell.execute_reply.started\":\"2022-02-08T06:50:42.820927Z\",\"shell.execute_reply\":\"2022-02-08T06:50:43.365521Z\"}}\n",
    "    directory = '../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms_beat/train'\n",
    "\n",
    "    fig = plt.figure(figsize = (10, 10))\n",
    "    spectrograms = []\n",
    "    for i in range(len(samples)):\n",
    "\n",
    "        filename = os.path.join(directory, samples[i])\n",
    "        ax = fig.add_subplot(2, 1, i + 1)\n",
    "        ax.set_xlabel('Time')\n",
    "        ax.set_ylabel('Frequency')\n",
    "\n",
    "        spectrogram = np.load(filename)[:128]\n",
    "        spectrograms.append(spectrogram)\n",
    "        print(f'Spectrogram time steps: {spectrogram.shape[1]}')\n",
    "\n",
    "        img = librosa.display.specshow(spectrogram, x_axis = 'time', y_axis='mel')\n",
    "\n",
    "        fig.colorbar(img, ax=ax, format ='% +2.f dB')\n",
    "        ax.set(title='Spectrogram for {}'.format(genre[i]))\n",
    "\n",
    "    # %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2022-02-08T06:50:43.367514Z\",\"iopub.execute_input\":\"2022-02-08T06:50:43.368272Z\",\"iopub.status.idle\":\"2022-02-08T06:50:43.887186Z\",\"shell.execute_reply.started\":\"2022-02-08T06:50:43.368232Z\",\"shell.execute_reply\":\"2022-02-08T06:50:43.886500Z\"}}\n",
    "    directory = '../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms/train/'\n",
    "    fig = plt.figure(figsize = (10, 10))\n",
    "    spectrograms = []\n",
    "    for i in range(len(samples)):\n",
    "\n",
    "        filename = os.path.join(directory, samples[i])\n",
    "        ax = fig.add_subplot(2, 1, i + 1)\n",
    "        ax.set_xlabel('Time')\n",
    "        ax.set_ylabel('Frequency')\n",
    "\n",
    "        spectrogram = np.load(filename)[128:]\n",
    "        spectrograms.append(spectrogram)\n",
    "        print(f'Spectrogram time steps: {spectrogram.shape[1]}')\n",
    "\n",
    "        img = librosa.display.specshow(spectrogram, x_axis = 'time', y_axis = 'mel')\n",
    "\n",
    "        fig.colorbar(img, ax=ax, format ='% +.2f dB')\n",
    "        ax.set(title='Chromogram for {}'.format(genre[i]))\n",
    "\n",
    "    # %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2022-02-08T06:50:43.888514Z\",\"iopub.execute_input\":\"2022-02-08T06:50:43.889314Z\",\"iopub.status.idle\":\"2022-02-08T06:50:44.374974Z\",\"shell.execute_reply.started\":\"2022-02-08T06:50:43.889273Z\",\"shell.execute_reply\":\"2022-02-08T06:50:44.374299Z\"}}\n",
    "    directory = '../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms_beat/train'\n",
    "\n",
    "    fig = plt.figure(figsize = (10, 10))\n",
    "    spectrograms = []\n",
    "    for i in range(len(samples)):\n",
    "\n",
    "        filename = os.path.join(directory, samples[i])\n",
    "        ax = fig.add_subplot(2, 1, i + 1)\n",
    "        ax.set_xlabel('Time')\n",
    "        ax.set_ylabel('Frequency')\n",
    "\n",
    "        spectrogram = np.load(filename)[128:]\n",
    "        spectrograms.append(spectrogram)\n",
    "        print(f'Spectrogram time steps: {spectrogram.shape[1]}')\n",
    "\n",
    "        img = librosa.display.specshow(spectrogram, x_axis = 'time', y_axis='mel')\n",
    "\n",
    "        fig.colorbar(img, ax=ax, format ='% +.2f dB')\n",
    "        ax.set(title='Chromogram for {}'.format(genre[i]))\n",
    "\n",
    "    # %% [markdown]\n",
    "    # Map similar classes together ignore underrepresented classes.\n",
    "\n",
    "    # %% [code] {\"execution\":{\"iopub.status.busy\":\"2022-02-08T06:50:44.376147Z\",\"iopub.execute_input\":\"2022-02-08T06:50:44.376939Z\",\"iopub.status.idle\":\"2022-02-08T06:50:44.385017Z\",\"shell.execute_reply.started\":\"2022-02-08T06:50:44.376897Z\",\"shell.execute_reply\":\"2022-02-08T06:50:44.384237Z\"}}\n",
    "    import copy\n",
    "    import os\n",
    "\n",
    "    import numpy as np\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    from torch.utils.data import DataLoader, Dataset, SubsetRandomSampler\n",
    "\n",
    "\n",
    "    # %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2022-02-08T06:50:44.544403Z\",\"iopub.execute_input\":\"2022-02-08T06:50:44.544836Z\",\"iopub.status.idle\":\"2022-02-08T06:51:32.858293Z\",\"shell.execute_reply.started\":\"2022-02-08T06:50:44.544639Z\",\"shell.execute_reply\":\"2022-02-08T06:51:32.853793Z\"}}\n",
    "    directory = '../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms/'\n",
    "\n",
    "    train_loader_mel, val_loader_mel, test_loader_mel = train_test_val_splitter(directory)\n",
    "\n",
    "    # %% [code] {\"execution\":{\"iopub.status.busy\":\"2022-02-08T06:51:32.862310Z\",\"iopub.execute_input\":\"2022-02-08T06:51:32.863718Z\",\"iopub.status.idle\":\"2022-02-08T06:51:44.964878Z\",\"shell.execute_reply.started\":\"2022-02-08T06:51:32.863661Z\",\"shell.execute_reply\":\"2022-02-08T06:51:44.964106Z\"},\"jupyter\":{\"outputs_hidden\":false}}\n",
    "    directory_beat = '../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms_beat/'\n",
    "\n",
    "    train_loader_beat_mel, val_loader_beat_mel, test_loader_beat_mel = train_test_val_splitter(directory_beat)\n",
    "\n",
    "    # %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2022-02-08T06:51:44.966153Z\",\"iopub.execute_input\":\"2022-02-08T06:51:44.966414Z\",\"iopub.status.idle\":\"2022-02-08T06:51:47.544861Z\",\"shell.execute_reply.started\":\"2022-02-08T06:51:44.966381Z\",\"shell.execute_reply\":\"2022-02-08T06:51:47.544106Z\"}}\n",
    "    directory_beat = '../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms_beat/'\n",
    "\n",
    "    train_loader_beat_chroma, val_loader_beat_chroma, test_loader_beat_chroma = train_test_val_splitter(directory_beat, chroma = True)\n",
    "\n",
    "    # %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2022-02-08T06:51:47.546239Z\",\"iopub.execute_input\":\"2022-02-08T06:51:47.546510Z\",\"iopub.status.idle\":\"2022-02-08T06:51:49.961608Z\",\"shell.execute_reply.started\":\"2022-02-08T06:51:47.546473Z\",\"shell.execute_reply\":\"2022-02-08T06:51:49.960847Z\"}}\n",
    "    train_loader, val_loader, test_loader = train_test_val_splitter(directory_beat, fused = True)\n",
    "\n",
    "    # %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2022-02-08T06:51:49.962820Z\",\"iopub.execute_input\":\"2022-02-08T06:51:49.965991Z\",\"iopub.status.idle\":\"2022-02-08T06:51:57.477460Z\",\"shell.execute_reply.started\":\"2022-02-08T06:51:49.965950Z\",\"shell.execute_reply\":\"2022-02-08T06:51:57.476752Z\"}}\n",
    "    beat_mel_specs_nomap = SpectrogramDataset(\n",
    "         directory_beat,\n",
    "         train=True,\n",
    "         max_length=-1,\n",
    "         read_spec=read_spectrogram,\n",
    "         chroma = False)\n",
    "\n",
    "    labels_before = []\n",
    "    for i in range(len(beat_mel_specs_nomap)):\n",
    "        _, label, _ = beat_mel_specs_nomap[i]\n",
    "        labels_before.append(label)\n",
    "\n",
    "    beat_mel_specs = SpectrogramDataset(\n",
    "         directory_beat,\n",
    "         train=True,\n",
    "         max_length=-1,\n",
    "         class_mapping = class_mapping,\n",
    "         read_spec=read_spectrogram,\n",
    "         chroma = False)\n",
    "\n",
    "    labels_after = []\n",
    "    for i in range(len(beat_mel_specs)):\n",
    "        _, label, _ = beat_mel_specs[i]\n",
    "        labels_after.append(label)\n",
    "\n",
    "    # %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2022-02-08T06:51:57.478617Z\",\"iopub.execute_input\":\"2022-02-08T06:51:57.480071Z\",\"iopub.status.idle\":\"2022-02-08T06:51:57.494731Z\",\"shell.execute_reply.started\":\"2022-02-08T06:51:57.480031Z\",\"shell.execute_reply\":\"2022-02-08T06:51:57.494079Z\"}}\n",
    "    datasets = {\n",
    "    'train_loader_mel': train_loader_mel,\n",
    "    'train_loader_beat_mel': train_loader_beat_mel,\n",
    "    'train_loader_beat_chroma': train_loader_beat_chroma,\n",
    "    'train_loader': train_loader,\n",
    "    'test_loader_mel': test_loader_mel,\n",
    "    'test_loader_beat_mel': test_loader_beat_mel,\n",
    "    'test_loader_beat_chroma': test_loader_beat_chroma,\n",
    "    'test_loader': test_loader,\n",
    "    'val_loader_mel': val_loader_mel,\n",
    "    'val_loader_beat_mel': val_loader_beat_mel,\n",
    "    'val_loader_beat_chroma': val_loader_beat_chroma,\n",
    "    'val_loader': val_loader}\n",
    "\n",
    "    # %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2022-02-08T06:51:57.496406Z\",\"iopub.execute_input\":\"2022-02-08T06:51:57.496674Z\",\"iopub.status.idle\":\"2022-02-08T06:51:57.893288Z\",\"shell.execute_reply.started\":\"2022-02-08T06:51:57.496639Z\",\"shell.execute_reply\":\"2022-02-08T06:51:57.892588Z\"}}\n",
    "    fig = plt.figure(figsize = (10, 10))\n",
    "    ax = fig.add_subplot(2, 1, 1)\n",
    "\n",
    "    ax.hist(labels_before)\n",
    "    ax.set_title('Before Mapping')\n",
    "\n",
    "    ax = fig.add_subplot(2, 1, 2)\n",
    "\n",
    "    ax.hist(labels_after)\n",
    "    ax.set_title('After Mapping')\n",
    "\n",
    "    # %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2022-02-08T06:51:57.894677Z\",\"iopub.execute_input\":\"2022-02-08T06:51:57.895758Z\",\"iopub.status.idle\":\"2022-02-08T06:51:57.900074Z\",\"shell.execute_reply.started\":\"2022-02-08T06:51:57.895433Z\",\"shell.execute_reply\":\"2022-02-08T06:51:57.899271Z\"}}\n",
    "    # Define useful parameters that are the same for all the models.\n",
    "    num_mel = 128\n",
    "    num_chroma = 12\n",
    "    n_classes = 10\n",
    "\n",
    "    # %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2022-02-08T06:51:57.901419Z\",\"iopub.execute_input\":\"2022-02-08T06:51:57.902290Z\",\"iopub.status.idle\":\"2022-02-08T06:52:17.971310Z\",\"shell.execute_reply.started\":\"2022-02-08T06:51:57.902251Z\",\"shell.execute_reply\":\"2022-02-08T06:52:17.970564Z\"}}\n",
    "    RNN_SIZE = 32\n",
    "    EPOCHS = 2000\n",
    "    model = BasicLSTM(num_mel, RNN_SIZE, n_classes, 1, bidirectional=True)\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "\n",
    "    DEVICE = torch.device('cuda')\n",
    "\n",
    "    model.double()\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    train_dataset(EPOCHS, train_loader_beat_mel, model, loss_function, optimizer, batch_overfit = True, model_name = './overfit_model')\n",
    "\n",
    "    # %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2022-02-08T06:52:17.972685Z\",\"iopub.execute_input\":\"2022-02-08T06:52:17.973089Z\",\"iopub.status.idle\":\"2022-02-08T06:53:09.472187Z\",\"shell.execute_reply.started\":\"2022-02-08T06:52:17.973050Z\",\"shell.execute_reply\":\"2022-02-08T06:53:09.471012Z\"}}\n",
    "    model = BasicLSTM(num_mel, 32, 10, 1, bidirectional=True)\n",
    "    train_eval_model(500, model, './mel_32_500', 'loader_mel')\n",
    "\n",
    "    # %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2022-02-08T06:53:09.473892Z\",\"iopub.execute_input\":\"2022-02-08T06:53:09.474163Z\",\"iopub.status.idle\":\"2022-02-08T06:54:51.458511Z\",\"shell.execute_reply.started\":\"2022-02-08T06:53:09.474126Z\",\"shell.execute_reply\":\"2022-02-08T06:54:51.457765Z\"}}\n",
    "    model = BasicLSTM(num_mel, 64, 10, 1, bidirectional=True)\n",
    "    train_eval_model(1000, model, './mel_64_1000', 'loader_mel')\n",
    "\n",
    "    # %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2022-02-08T06:54:51.460139Z\",\"iopub.execute_input\":\"2022-02-08T06:54:51.460661Z\",\"iopub.status.idle\":\"2022-02-08T06:54:56.913416Z\",\"shell.execute_reply.started\":\"2022-02-08T06:54:51.460621Z\",\"shell.execute_reply\":\"2022-02-08T06:54:56.912717Z\"}}\n",
    "    model = BasicLSTM(num_mel, 32, 10, 1, bidirectional=True)\n",
    "    train_eval_model(500,model, './beat_mel_32_500', 'loader_beat_mel')\n",
    "\n",
    "    # %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2022-02-08T06:54:56.914795Z\",\"iopub.execute_input\":\"2022-02-08T06:54:56.915622Z\",\"iopub.status.idle\":\"2022-02-08T06:55:08.681901Z\",\"shell.execute_reply.started\":\"2022-02-08T06:54:56.915584Z\",\"shell.execute_reply\":\"2022-02-08T06:55:08.681046Z\"}}\n",
    "    model = BasicLSTM(num_mel, 64, 10, 1, bidirectional=True)\n",
    "    train_eval_model(1000, model, './beat_mel_64_1000', 'loader_beat_mel')\n",
    "\n",
    "    # %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2022-02-08T06:55:08.683129Z\",\"iopub.execute_input\":\"2022-02-08T06:55:08.685875Z\",\"iopub.status.idle\":\"2022-02-08T06:55:13.779169Z\",\"shell.execute_reply.started\":\"2022-02-08T06:55:08.685831Z\",\"shell.execute_reply\":\"2022-02-08T06:55:13.777692Z\"}}\n",
    "    model = BasicLSTM(num_chroma, 32, 10, 1, bidirectional=True)\n",
    "    train_eval_model(500, model, './beat_chroma_32_500', 'loader_beat_chroma')\n",
    "\n",
    "    # %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2022-02-08T06:55:13.780615Z\",\"iopub.execute_input\":\"2022-02-08T06:55:13.780882Z\",\"iopub.status.idle\":\"2022-02-08T06:55:24.514526Z\",\"shell.execute_reply.started\":\"2022-02-08T06:55:13.780845Z\",\"shell.execute_reply\":\"2022-02-08T06:55:24.513786Z\"}}\n",
    "    model = BasicLSTM(num_chroma, 64, 10, 1, bidirectional=True)\n",
    "    train_eval_model(1000, model, './beat_chroma_64_1000', 'loader_beat_chroma')\n",
    "\n",
    "    # %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2022-02-08T06:55:24.515658Z\",\"iopub.execute_input\":\"2022-02-08T06:55:24.516057Z\",\"iopub.status.idle\":\"2022-02-08T06:55:30.083081Z\",\"shell.execute_reply.started\":\"2022-02-08T06:55:24.516020Z\",\"shell.execute_reply\":\"2022-02-08T06:55:30.082310Z\"}}\n",
    "    model = BasicLSTM(num_chroma + num_mel, 32, 10, 1, bidirectional=True)\n",
    "    train_eval_model(500, model, './fused_32_500', 'loader')\n",
    "\n",
    "    # %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2022-02-08T06:55:30.100806Z\",\"iopub.execute_input\":\"2022-02-08T06:55:30.101138Z\",\"iopub.status.idle\":\"2022-02-08T06:55:30.111431Z\",\"shell.execute_reply.started\":\"2022-02-08T06:55:30.101096Z\",\"shell.execute_reply\":\"2022-02-08T06:55:30.110574Z\"}}\n",
    "    model = net\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.double()\n",
    "    model.to(DEVICE)\n",
    "    loss_function = nn.CrossEntropyLoss().to(DEVICE)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5).to(DEVICE)\n",
    "    EPOCHS = np.linspace(500, 1500, 3)\n",
    "\n",
    "    # %% [markdown]\n",
    "    # # MNIST ConvNetJS \n",
    "    # The model trained has the following layers:\n",
    "    # * 2 Convolution layers with a ReLU activation function, stride = 1, pad = 2, num_filters = 8, 16 respectively.\n",
    "    # * 2 Pool Layers with max pooling, stride = 2, stride = 3\n",
    "    # * FC layer with softmax activation\n",
    "    # \n",
    "    # \n",
    "    # ## Convolution Layer: \n",
    "    # This layer is used to filter the image by applying learnable weights to a subset of the inout matrix.\n",
    "    # In this model the first layer uses 6 5 by 5 filters and the second 16 5 by 5 filters. By filtering the image we achieve a form of feature selection from the initial image. The end result for every filter is called feature map, as it maps the initial image to some of its significant features. After that we use ReLU.\n",
    "    # \n",
    "    # ## ReLU activation function:\n",
    "    # The convolution operator used above is a linear operator. While useful for feature selection, real data exhibit great nonlinearity. Therefore we need to add some form of nonlinearity to our model, which is what ReLU accomplises.\n",
    "    # \n",
    "    # ## Pool Layer:\n",
    "    # Pooling or specifically max pooling selects the biggest value inside in a spatial area defined by pooling size. In our case we use 8 2 by 2 matrices in the pooling layer. The main utilities of pooling are:\n",
    "    # \n",
    "    # * Decreasing the number of parameters and computations making the model manageable and controlling overfitting.\n",
    "    # * Makes the model invariant to small variations in the input data.\n",
    "    # \n",
    "    # ## Fully Connected Layer:\n",
    "    # This layer is basically an MLP with the use of a softmax activation function in the end.\n",
    "    # The purpose of this layer is to classify the image shown in a specifc digit (0-9).\n",
    "    # The output from the convolution and pooling layer represents high-level features which are then used by the fully connected layer to predict the digit shown.\n",
    "\n",
    "    # %% [code] {\"jupyter\":{\"outputs_hidden\":false}}'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 449.542785,
   "end_time": "2022-02-20T21:26:19.224096",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-02-20T21:18:49.681311",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
